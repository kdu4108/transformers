{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f298f02b4b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "import brunoflow as bf\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  7592,  1045,  2215,  2000,  4521,  2070,   103,  6240,  2651,\n",
      "          1012,  2009,  1005,  1055, 15060,   103,  2035,   999,   102],\n",
      "        [  101, 10930, 10930,  2054,  1005,  1055,  2039,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# Establish data\n",
    "model_id = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_id)\n",
    "text = [\"hello I want to eat some [MASK] meat today. It's thanksgiving [MASK] all!\", \"yo yo what's up\"]\n",
    "\n",
    "# tokenize text and pass into model\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BfBertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 128)\n",
      "  (token_type_embeddings): Embedding(2, 128)\n",
      "  (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0)\n",
      ")\n",
      "BertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 128)\n",
      "  (token_type_embeddings): Embedding(2, 128)\n",
      "  (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/code/rycolab/transformers/src/transformers/models/bert/modeling_bf_bert.py:170: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  \"token_type_ids\", bf.Node(jnp.zeros(self.position_ids.shape, dtype=jnp.int64)), persistent=False\n"
     ]
    }
   ],
   "source": [
    "# Create BfBertEmbeddings and BertEmbeddings\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"../../brunoflow/models/bert/config-tiny.json\")\n",
    "bf_embs = BfBertEmbeddings(config)\n",
    "torch_embs = BertEmbeddings(config)\n",
    "print(bf_embs)\n",
    "print(torch_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertEmbeddings to file\n",
    "save_path = \"bertembeddings_torch.pt\"\n",
    "torch.save(torch_embs.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load torch BertEmbeddings into bf\n",
    "bf_embs.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BfBertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 128)\n",
       "  (token_type_embeddings): Embedding(2, 128)\n",
       "  (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that bert embedding values loaded correctly into bf and they match the torch vals \n",
    "assert(check_node_equals_tensor(bf_embs.word_embeddings.weight, torch_embs.word_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.position_embeddings.weight, torch_embs.position_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.token_type_embeddings.weight, torch_embs.token_type_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.LayerNorm.weight, torch_embs.LayerNorm.weight))\n",
    "# print(check_node_equals_tensor(bf_embs.dropout.weight, torch_embs.dropout.weight)) # this fails because dropout has no weights, I guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how much changing the precision affects the gradient\n",
    "# for name, param in bf_embs.named_parameters():\n",
    "#     param.val = jnp.round(param.val, 3)\n",
    "#     print(name, param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare output of forward pass of BfBertEmbeddings and BertEmbeddings on the text - they're equal!\n",
    "jax_input_ids = jnp.array(input_ids.numpy(), dtype=int)\n",
    "torch_embs.train(False)\n",
    "bf_embs.train(False)\n",
    "\n",
    "out_bf = bf_embs(input_ids=jax_input_ids)\n",
    "out_torch = torch_embs(input_ids=input_ids)\n",
    "# print(out_bf.val)\n",
    "# print(out_torch)\n",
    "# print(out_bf.val - out_torch.detach().numpy())\n",
    "assert(check_node_allclose_tensor(out_bf, out_torch, atol=1e-3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare grads of parameters between torch and bf after a backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 ms, sys: 69 Âµs, total: 4.27 ms\n",
      "Wall time: 2.97 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Torch backward pass\n",
    "torch_embs.train(True)\n",
    "out_torch.backward(gradient=torch.ones_like(out_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 342 ms, total: 2.6 s\n",
      "Wall time: 4.69 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BF backward pass\n",
    "out_bf.backprop(values_to_compute=(\"grad\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"word_embeddings:\", bf_embs.word_embeddings.weight.grad, torch_embs.word_embeddings.weight.grad)\n",
    "# print(\"position_embeddings:\", bf_embs.position_embeddings.weight.grad, torch_embs.position_embeddings.weight.grad)\n",
    "# print(\"token_type_embeddings:\", bf_embs.token_type_embeddings.weight.grad, torch_embs.token_type_embeddings.weight.grad)\n",
    "# print(\"LayerNorm:\", bf_embs.LayerNorm.weight.grad, torch_embs.LayerNorm.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad of param word_embeddings.weight for bf and torch are within 1e-6? True\n",
      "Grad of param position_embeddings.weight for bf and torch are within 1e-6? True\n",
      "Grad of param token_type_embeddings.weight for bf and torch are within 1e-6? True\n",
      "Grad of param LayerNorm.weight for bf and torch are within 1e-6? True\n",
      "Grad of param LayerNorm.bias for bf and torch are within 1e-6? True\n"
     ]
    }
   ],
   "source": [
    "bf_emb_params = {name: param for name, param in bf_embs.named_parameters()}\n",
    "torch_emb_params = {name: param for name, param in torch_embs.named_parameters()}\n",
    "assert set(bf_emb_params.keys()) == set(torch_emb_params.keys())\n",
    "\n",
    "for name in bf_emb_params.keys():\n",
    "    print(f\"Grad of param {name} for bf and torch are within 1e-6? {jnp.allclose(bf_emb_params[name].grad, torch_emb_params[name].grad.numpy(), atol=1e-6)}\")\n",
    "    assert jnp.allclose(bf_emb_params[name].grad, torch_emb_params[name].grad.numpy(), atol=1e-6), f\"Grad of param {name} for bf and torch are not within 1e-6.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([ 56.536148  ,   9.873916  ,  -9.946613  ,  29.669815  ,\n",
       "              -19.766806  ,   4.3356705 , -23.152435  , -29.78961   ,\n",
       "              -18.999136  ,  36.90544   , -35.539238  , -37.673416  ,\n",
       "               27.412798  ,   0.0662511 ,  13.515636  ,  -9.084731  ,\n",
       "               -9.820608  , -51.483334  ,  10.379288  ,  26.532597  ,\n",
       "               -2.8499513 ,  10.431053  ,   5.990584  , -41.563046  ,\n",
       "                8.451949  ,  42.47052   ,   6.350166  ,  -6.573671  ,\n",
       "               -1.4423742 ,  37.940216  ,  52.01646   ,  23.367987  ,\n",
       "               -6.191135  ,   0.69063747,  -8.358557  ,  43.680916  ,\n",
       "               10.069973  ,  -4.429394  , -37.8228    ,  -1.1591048 ,\n",
       "               24.835108  , -44.698177  , -19.027328  , -22.159668  ,\n",
       "               -3.9408004 ,   0.2023251 , -10.610362  ,   0.97283334,\n",
       "               25.851631  , -22.99358   ,  -2.786594  , -51.906845  ,\n",
       "               -7.4670386 ,   8.02406   , -54.158016  ,  19.590197  ,\n",
       "               27.291925  ,   0.33671165, -32.04782   ,  22.110023  ,\n",
       "               57.535984  ,  -8.57379   , -11.209441  ,  14.142599  ,\n",
       "                2.1159832 ,  -9.329752  ,  -4.9822206 ,  25.393856  ,\n",
       "               25.380583  , -20.16127   , -19.098679  , -53.229496  ,\n",
       "               21.851423  , -38.642677  ,  -8.245297  ,  -5.1999884 ,\n",
       "               -3.2136543 ,  -0.2979834 , -10.521454  ,  30.148548  ,\n",
       "               23.784363  , -20.495758  ,   1.5883768 ,  15.164824  ,\n",
       "              -30.625395  ,   4.939541  ,   0.2525158 ,   0.81552315,\n",
       "              -17.716776  ,   5.976165  ,  21.422852  ,  -2.371808  ,\n",
       "              -29.102297  ,  -3.3545425 ,   5.091766  ,   5.696533  ,\n",
       "               35.90091   ,  17.130508  ,   4.584667  ,  32.35907   ,\n",
       "              -12.420339  , -23.607985  ,  31.148603  ,  14.662947  ,\n",
       "              -11.345839  , -14.532167  , -13.222213  , -18.595032  ,\n",
       "               44.57676   ,  22.464663  ,  41.065014  ,   9.054272  ,\n",
       "               11.362236  ,  33.918144  ,  12.596973  ,  13.409921  ,\n",
       "              -16.611809  , -43.710922  ,  -8.444263  ,  -1.9683843 ,\n",
       "               -3.093223  , -44.41162   ,  26.90382   , -27.983812  ,\n",
       "              -40.990704  ,  -2.5969498 ,   6.076511  ,   2.930428  ],            dtype=float32),\n",
       " array([ 56.53615   ,   9.873918  ,  -9.946615  ,  29.669817  ,\n",
       "        -19.766804  ,   4.3356705 , -23.152433  , -29.78961   ,\n",
       "        -18.999136  ,  36.90544   , -35.539238  , -37.673416  ,\n",
       "         27.412798  ,   0.06625086,  13.5156355 ,  -9.084731  ,\n",
       "         -9.820608  , -51.48334   ,  10.379286  ,  26.532595  ,\n",
       "         -2.8499515 ,  10.431051  ,   5.9905834 , -41.56304   ,\n",
       "          8.451948  ,  42.470524  ,   6.350167  ,  -6.57367   ,\n",
       "         -1.4423742 ,  37.940212  ,  52.01646   ,  23.367987  ,\n",
       "         -6.1911354 ,   0.69063765,  -8.358556  ,  43.680916  ,\n",
       "         10.069974  ,  -4.4293933 , -37.822803  ,  -1.1591051 ,\n",
       "         24.835108  , -44.698174  , -19.027327  , -22.159664  ,\n",
       "         -3.9408002 ,   0.20232487, -10.610362  ,   0.97283304,\n",
       "         25.851631  , -22.993578  ,  -2.7865949 , -51.90685   ,\n",
       "         -7.4670386 ,   8.02406   , -54.15801   ,  19.590193  ,\n",
       "         27.291927  ,   0.33671165, -32.04782   ,  22.110022  ,\n",
       "         57.535988  ,  -8.57379   , -11.209441  ,  14.142598  ,\n",
       "          2.1159837 ,  -9.329754  ,  -4.9822206 ,  25.393854  ,\n",
       "         25.380585  , -20.161272  , -19.098679  , -53.229492  ,\n",
       "         21.851425  , -38.64268   ,  -8.2452965 ,  -5.1999884 ,\n",
       "         -3.2136538 ,  -0.29798377, -10.521453  ,  30.148552  ,\n",
       "         23.784365  , -20.495756  ,   1.5883765 ,  15.164822  ,\n",
       "        -30.625399  ,   4.93954   ,   0.25251555,   0.8155225 ,\n",
       "        -17.716776  ,   5.9761634 ,  21.42285   ,  -2.371807  ,\n",
       "        -29.102303  ,  -3.3545418 ,   5.0917664 ,   5.6965327 ,\n",
       "         35.90091   ,  17.13051   ,   4.584666  ,  32.35907   ,\n",
       "        -12.42034   , -23.607983  ,  31.148602  ,  14.662946  ,\n",
       "        -11.345838  , -14.532168  , -13.222213  , -18.595032  ,\n",
       "         44.576763  ,  22.464664  ,  41.065014  ,   9.05427   ,\n",
       "         11.362237  ,  33.918144  ,  12.596975  ,  13.40992   ,\n",
       "        -16.611805  , -43.71092   ,  -8.444265  ,  -1.9683845 ,\n",
       "         -3.093223  , -44.41162   ,  26.903818  , -27.983812  ,\n",
       "        -40.990707  ,  -2.5969493 ,   6.0765123 ,   2.9304276 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bf_emb_params[\"LayerNorm.weight\"].grad, torch_emb_params[\"LayerNorm.weight\"].grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('jax-hf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
