{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b947240b3b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import brunoflow as bf\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  7592,  1045,  2215,  2000,  4521,  2070,   103,  6240,  2651,\n",
      "          1012,  2009,  1005,  1055, 15060,   103,  2035,   999,   102],\n",
      "        [  101, 10930, 10930,  2054,  1005,  1055,  2039,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# Establish data\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "text = [\"hello I want to eat some [MASK] meat today. It's thanksgiving [MASK] all!\", \"yo yo what's up\"]\n",
    "\n",
    "# tokenize text and pass into model\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 00:40:47.961439: W external/org_tensorflow/tensorflow/compiler/xla/service/platform_util.cc:193] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/cluster/work/cotterell/kdu/transformers/src/transformers/models/bert/modeling_bf_bert.py:175: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  self.register_buffer(\"token_type_ids\", bf.Node(jnp.zeros(self.position_ids.shape, dtype=jnp.int64)), persistent=False) # todo is this 64 bit necessary?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BfBertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 768)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      ")\n",
      "BertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 768)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create BfBertEmbeddings and BertEmbeddings\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"../../brunoflow/models/bert/config.json\")\n",
    "bf_embs = BfBertEmbeddings(config)\n",
    "torch_embs = BertEmbeddings(config)\n",
    "print(bf_embs)\n",
    "print(torch_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertEmbeddings to file\n",
    "save_path = \"bertembeddings_torch.pt\"\n",
    "torch.save(torch_embs.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load torch BertEmbeddings into bf\n",
    "bf_embs.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BfBertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that bert embedding values loaded correctly into bf and they match the torch vals \n",
    "assert(check_node_equals_tensor(bf_embs.word_embeddings.weight, torch_embs.word_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.position_embeddings.weight, torch_embs.position_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.token_type_embeddings.weight, torch_embs.token_type_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.LayerNorm.weight, torch_embs.LayerNorm.weight))\n",
    "# print(check_node_equals_tensor(bf_embs.dropout.weight, torch_embs.dropout.weight)) # this fails because dropout has no weights, I guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare output of forward pass of BfBertEmbeddings and BertEmbeddings on the text - they're equal!\n",
    "jax_input_ids = jnp.array(input_ids.numpy(), dtype=int)\n",
    "torch_embs.train(False)\n",
    "out_bf = bf_embs(input_ids=jax_input_ids)\n",
    "out_torch = torch_embs(input_ids=input_ids)\n",
    "# print(out_bf.val)\n",
    "# print(out_torch)\n",
    "assert(check_node_allclose_tensor(out_bf, out_torch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare grads of parameters between torch and bf after a backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Torch backward pass\n",
    "torch_embs.train(True)\n",
    "out_torch.backward(gradient=torch.ones_like(out_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 12.6 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "# BF backward pass\n",
    "out_bf.backprop(values_to_compute=(\"grad\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"word_embeddings:\", bf_embs.word_embeddings.weight.grad, torch_embs.word_embeddings.weight.grad)\n",
    "# print(\"position_embeddings:\", bf_embs.position_embeddings.weight.grad, torch_embs.position_embeddings.weight.grad)\n",
    "# print(\"token_type_embeddings:\", bf_embs.token_type_embeddings.weight.grad, torch_embs.token_type_embeddings.weight.grad)\n",
    "# print(\"LayerNorm:\", bf_embs.LayerNorm.weight.grad, torch_embs.LayerNorm.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad of param word_embeddings.weight for bf and torch are within 1e-6? True\n",
      "Grad of param position_embeddings.weight for bf and torch are within 1e-6? True\n",
      "Grad of param token_type_embeddings.weight for bf and torch are within 1e-6? True\n",
      "Grad of param LayerNorm.weight for bf and torch are within 1e-6? True\n",
      "Grad of param LayerNorm.bias for bf and torch are within 1e-6? True\n"
     ]
    }
   ],
   "source": [
    "bf_emb_params = {name: param for name, param in bf_embs.named_parameters()}\n",
    "torch_emb_params = {name: param for name, param in torch_embs.named_parameters()}\n",
    "assert set(bf_emb_params.keys()) == set(torch_emb_params.keys())\n",
    "\n",
    "for name in bf_emb_params.keys():\n",
    "    print(f\"Grad of param {name} for bf and torch are within 1e-6? {jnp.allclose(bf_emb_params[name].grad, torch_emb_params[name].grad.numpy(), atol=1e-6)}\")\n",
    "    assert jnp.allclose(bf_emb_params[name].grad, torch_emb_params[name].grad.numpy(), atol=1e-6), f\"Grad of param {name} for bf and torch are not within 1e-6.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax3.10",
   "language": "python",
   "name": "jax3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
