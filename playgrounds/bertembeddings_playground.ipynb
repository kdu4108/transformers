{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fde003d8470>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import brunoflow as bf\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  7592,  1045,  2215,  2000,  4521,  2070,   103,  6240,  2651,\n",
      "          1012,  2009,  1005,  1055, 15060,   103,  2035,   999,   102],\n",
      "        [  101, 10930, 10930,  2054,  1005,  1055,  2039,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# Establish data\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "text = [\"hello I want to eat some [MASK] meat today. It's thanksgiving [MASK] all!\", \"yo yo what's up\"]\n",
    "\n",
    "# tokenize text and pass into model\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 18:07:11.873060: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BfBertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 768)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      ")\n",
      "BertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 768)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/code/rycolab/transformers/src/transformers/models/bert/modeling_bf_bert.py:175: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  self.register_buffer(\"token_type_ids\", bf.Node(jnp.zeros(self.position_ids.shape, dtype=jnp.int64)), persistent=False) # todo is this 64 bit necessary?\n"
     ]
    }
   ],
   "source": [
    "# Create BfBertEmbeddings and BertEmbeddings\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"/home/kevin/code/rycolab/brunoflow/models/bert/config.json\")\n",
    "bf_embs = BfBertEmbeddings(config)\n",
    "torch_embs = BertEmbeddings(config)\n",
    "print(bf_embs)\n",
    "print(torch_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertEmbeddings to file\n",
    "save_path = \"bertembeddings_torch.pt\"\n",
    "torch.save(torch_embs.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load torch BertEmbeddings into bf\n",
    "bf_embs.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BfBertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(check_node_equals_tensor(bf_embs.word_embeddings.weight, torch_embs.word_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.position_embeddings.weight, torch_embs.position_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.token_type_embeddings.weight, torch_embs.token_type_embeddings.weight))\n",
    "assert(check_node_equals_tensor(bf_embs.LayerNorm.weight, torch_embs.LayerNorm.weight))\n",
    "# print(check_node_equals_tensor(bf_embs.dropout.weight, torch_embs.dropout.weight)) # this fails because dropout has no weights, I guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.7684e-07, -4.7684e-07, -4.7684e-07,  ..., -4.7684e-07,\n",
      "         -4.7684e-07, -4.7684e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] tensor([[-2.6226e-06, -2.6226e-06, -2.6226e-06,  ..., -2.6226e-06,\n",
      "         -2.6226e-06, -2.6226e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] tensor([ 3.2099e+01, -3.0429e+01, -5.3910e+01, -7.6205e+00,  2.5015e+01,\n",
      "         1.3616e+02, -4.1036e+01, -6.5001e+01, -1.1084e+02, -9.4306e+01,\n",
      "        -1.1487e+02,  3.9919e+01,  7.3372e+01, -2.8352e+01, -1.0827e+02,\n",
      "        -9.3155e+01,  8.2581e+01, -7.6531e+01,  1.2086e+01,  9.4870e+01,\n",
      "         7.3652e+01,  1.4746e+02,  6.5542e+01,  1.2513e+00,  3.0993e+02,\n",
      "         1.3580e+02, -2.4507e+01, -2.0336e+02,  3.5371e+01,  8.4360e+00,\n",
      "        -1.0550e+02, -1.3831e+01, -8.1547e+01, -1.3057e+02, -7.3811e+01,\n",
      "         6.8791e+01, -1.1141e+02,  1.2646e+02, -9.6220e+01, -7.5231e+01,\n",
      "        -4.2407e+01,  3.6554e+01,  2.6604e+01,  1.3029e+02,  9.8483e+01,\n",
      "         1.9517e+02, -6.4747e+01,  2.9921e+01, -3.2155e+01,  1.1429e+01,\n",
      "        -4.2751e+01,  2.1577e+02,  3.1677e+01,  1.1712e+02, -2.8738e+01,\n",
      "         7.8627e+01, -1.8018e+02,  7.9027e+01,  7.0051e+01,  5.2428e+01,\n",
      "         1.6254e+02,  2.0553e+02,  1.2648e+02,  3.4409e+01,  1.0240e+02,\n",
      "         4.5757e+01,  8.3110e+01,  3.0544e+00,  1.1989e+02, -1.1133e+02,\n",
      "        -5.8244e+01, -6.6681e+01,  8.1633e+01,  1.3847e+02,  7.8637e+01,\n",
      "         7.5288e+01, -5.6660e+01, -6.9484e+00,  1.0830e+02,  2.4460e+01,\n",
      "        -3.0056e+00,  7.1440e+01,  1.3073e+02,  1.5983e+02,  1.2089e+02,\n",
      "         1.6796e+02,  8.5479e+00, -5.0983e+01,  9.5837e+01, -7.6529e+01,\n",
      "        -1.2338e+02, -7.5860e+01,  8.4888e+01,  3.2433e+01, -6.2916e+01,\n",
      "        -3.8692e+01, -1.8383e+01, -9.9908e+01,  3.6332e+01,  8.8367e+01,\n",
      "        -1.6362e+02,  1.6869e+02,  2.2825e+02,  2.5135e+02,  1.0412e+02,\n",
      "         2.2837e+01,  1.6050e+02,  2.1138e+02,  1.4684e+02, -8.0395e+01,\n",
      "         4.9414e+01,  1.5660e+02,  6.3022e+01,  6.4786e+00, -4.7123e+01,\n",
      "        -1.1384e+02, -8.1594e+01, -6.7341e+01, -6.9534e+01,  4.8482e+01,\n",
      "         3.8805e+01, -9.0552e+00, -8.1089e+01, -2.9980e+01, -1.3138e+02,\n",
      "         7.7437e+01, -3.2927e+01,  9.4595e+00, -3.8086e+01,  1.0209e+01,\n",
      "         1.4912e+02, -6.6754e+01, -1.5992e+02, -2.7862e+01, -5.6659e+01,\n",
      "         7.3216e+01, -1.1525e+02,  1.7073e+01,  1.7387e+02,  1.1945e+02,\n",
      "         4.7541e+00, -4.0486e+01, -8.2043e+01,  5.9732e+01,  1.0844e+02,\n",
      "         4.3577e+01,  1.7283e+02,  1.6764e+02, -6.6230e+01, -1.0197e+01,\n",
      "         3.5358e+01, -1.4863e+02, -2.4082e+01, -1.3199e+01, -2.0747e+02,\n",
      "        -9.6735e+01, -9.0879e+01,  1.9350e+01,  4.4779e+01,  1.6265e+02,\n",
      "        -2.0717e+02,  2.2246e+01, -4.1653e+01,  8.2387e+00, -6.2927e+01,\n",
      "        -4.5393e+01, -1.8735e+02,  2.0455e+02,  3.3533e+01, -8.6153e+01,\n",
      "        -1.9417e+02, -7.0719e+01,  7.6889e+01,  5.7512e+01, -1.3716e+02,\n",
      "         2.8052e+01,  6.1298e+01, -1.6688e+01,  1.1687e+02,  9.8326e+01,\n",
      "        -9.9809e+00,  8.1104e+01, -9.2290e+01,  1.0238e+02, -1.4426e+01,\n",
      "        -1.5208e+02, -1.8607e+02,  1.5365e+02, -9.1742e+01, -1.2399e+02,\n",
      "        -2.1989e+02, -8.5835e+01, -1.2983e+02, -2.3213e+02, -9.3248e+01,\n",
      "        -5.9636e+01,  1.0926e+02,  2.9669e-03, -9.0572e+01,  2.3247e+01,\n",
      "        -4.0814e+01,  4.7970e+01,  8.0114e+01,  5.0220e+00, -7.4578e+01,\n",
      "         9.9843e+01, -3.4876e+01, -2.7936e+01,  6.7287e+01,  6.0084e+01,\n",
      "        -4.8280e+01, -3.2349e+01,  1.3399e+02,  1.9223e+01, -5.6226e+00,\n",
      "         7.6222e+01, -9.2554e+01, -2.2865e+02,  7.4197e+01,  1.1578e+02,\n",
      "        -9.1734e+01, -1.7732e+02,  4.1307e+01,  1.0410e+01, -1.3921e+02,\n",
      "         1.8897e+01, -4.6136e+01,  6.6063e+01,  2.1617e+02, -6.8944e+01,\n",
      "        -1.4105e+02, -1.4526e+02, -5.2471e+01, -1.9485e+01,  6.0039e+01,\n",
      "        -1.1593e+01, -7.5582e+01,  7.4477e+01,  7.9944e+01, -1.5373e+02,\n",
      "         8.3370e+01, -1.2234e+02,  2.5404e+00,  6.9392e+01, -5.1601e+01,\n",
      "         8.4405e+01, -3.1989e+01, -5.2207e+01,  7.8188e+01,  1.0854e+01,\n",
      "        -8.8106e+01, -9.0308e+01,  8.2058e+01, -5.9346e+01,  6.7642e+01,\n",
      "        -5.9412e+01,  9.8282e+00,  9.9607e+01,  2.2122e+01, -1.1424e+02,\n",
      "        -1.3291e+02, -7.6964e+01,  1.4806e+01,  4.2426e+01, -3.8726e+01,\n",
      "        -2.4960e+02, -4.7983e+01, -1.4244e+02,  3.3529e+01,  1.4266e+02,\n",
      "         7.5022e+00, -4.4305e+01, -1.3688e+02,  2.1384e+02, -8.8811e+01,\n",
      "        -1.5449e+02, -7.3418e+01,  1.7652e+01,  1.3015e+02, -1.1400e+02,\n",
      "         1.1848e+02, -1.6439e+01,  1.1662e+02,  2.0717e+02, -6.3647e+01,\n",
      "         1.1107e+02,  1.2230e+02,  1.2559e+02, -9.7116e+01,  9.8750e+01,\n",
      "        -3.3415e+01, -1.2437e+02, -2.3561e+02,  2.4544e+01,  2.6981e+01,\n",
      "        -8.3262e+01, -8.0954e+01,  4.1214e+01,  1.0099e+02,  6.5218e+01,\n",
      "         4.1765e+01,  6.0646e+01,  5.9208e+01, -2.0002e+02,  3.6608e+01,\n",
      "         1.0941e+02, -4.0705e+01, -5.4703e+01, -1.2381e+02,  8.6126e+00,\n",
      "        -1.1137e+02, -1.0039e+02, -3.1610e+01,  1.4234e+00,  3.7264e+01,\n",
      "         1.0283e+02,  1.5203e+02,  1.6193e+02, -1.9890e+02, -6.8733e+01,\n",
      "        -9.1599e+01, -4.7150e+01, -1.5023e+00,  6.7651e+01,  1.6720e+01,\n",
      "        -1.7960e+01, -7.9311e+01, -3.5755e+01,  1.7890e+01,  5.3786e+01,\n",
      "        -2.4212e+01,  7.0344e+01, -1.0928e+02, -1.2177e+02, -1.8321e+02,\n",
      "         4.5095e+01, -7.4682e+01,  1.2019e+02,  1.6830e+02, -1.9450e+00,\n",
      "         3.4541e+01, -1.3993e+02, -1.1621e+02, -2.8143e+01, -2.6476e+00,\n",
      "         1.8634e+02, -9.1373e+01,  1.7003e+02,  1.4825e+01, -9.2754e+01,\n",
      "         1.9432e+00, -1.8144e+02,  1.4598e+01,  6.1547e+01, -2.8568e+01,\n",
      "        -7.7080e+01, -9.5504e+01,  5.1839e+01, -4.8384e+01,  4.6271e+01,\n",
      "        -2.3706e+01, -3.5744e+01,  1.0133e+01,  1.1845e+02, -3.7407e+01,\n",
      "         9.4690e+01, -6.3084e+01,  1.4361e+01, -1.5713e+02,  1.1859e+02,\n",
      "        -6.9210e+01,  1.2764e+02, -9.3937e+01, -5.6460e+01, -5.2156e+01,\n",
      "        -1.0585e+02, -5.0493e+01,  8.1970e+00, -1.7325e+02,  1.9696e+00,\n",
      "         3.9940e+01,  8.8709e+01,  4.1901e+01, -3.6264e+01,  2.2788e+02,\n",
      "        -1.3919e+02,  7.6315e+01,  7.5953e+00, -7.3529e+00, -2.1248e+00,\n",
      "        -7.3787e+01,  1.2895e+02,  2.4172e-01, -8.7358e+00,  7.0714e+01,\n",
      "        -3.7776e+01,  5.8270e+01,  9.2755e+01,  5.9693e+01,  5.2624e+00,\n",
      "        -1.0034e+02, -1.2193e+02,  2.0227e+02,  2.2671e+02, -6.3713e+01,\n",
      "         2.6794e+02,  1.6781e+01,  2.9526e+01,  3.1506e+01,  7.0601e+01,\n",
      "        -2.3319e+01, -9.9331e+01,  8.6120e+01, -5.3349e+01,  1.0023e+02,\n",
      "         1.0211e+02, -6.7086e+01, -8.1800e+01, -9.8398e+01,  2.6585e+01,\n",
      "        -4.7862e+01,  6.7212e+01,  1.6953e+02,  1.9176e+02,  1.2052e+02,\n",
      "         9.8748e+01,  1.8962e+02, -1.2799e+02,  7.9427e+01,  6.1874e+00,\n",
      "        -4.8727e+01,  1.4009e+02,  6.9670e+01,  1.0483e+02,  6.0299e+01,\n",
      "        -3.3678e+01,  6.5287e+01,  2.3815e+02,  1.6495e+02, -8.7358e+01,\n",
      "         8.9391e+01, -8.6544e+00, -1.7847e+02, -1.4009e+01,  1.6126e+01,\n",
      "         2.0380e+02, -2.5271e+01, -1.3109e+02, -1.2770e+02, -4.9532e+01,\n",
      "        -6.1319e+01, -3.6085e+01, -1.4377e+02,  1.0382e+02, -6.6419e+01,\n",
      "        -1.7199e+01, -1.1196e+02,  2.1528e+02,  7.8837e+01, -1.4420e+02,\n",
      "        -1.7911e+02,  1.3678e+02, -9.3278e+01, -9.5656e+01,  5.0955e+01,\n",
      "         1.4173e+02,  6.3239e+01, -9.8517e+00,  2.2195e+01, -9.3262e+00,\n",
      "         1.1737e+02,  3.8864e+01,  2.7942e+01,  4.6949e+01, -8.8599e+01,\n",
      "        -8.1507e+01, -4.2101e+01, -3.6905e+01,  7.2826e+01, -9.7576e+01,\n",
      "         8.1920e+01, -2.0634e+00, -1.7915e+01, -1.7693e+01,  7.6169e+00,\n",
      "         1.2247e+00,  1.5972e+02, -9.9737e+01, -4.0973e+01, -1.1578e+02,\n",
      "         2.7895e+01,  4.7650e+01,  6.7691e+01, -1.0843e+01,  4.8284e+01,\n",
      "         1.8087e+02, -1.1215e+02,  1.8058e+00, -1.5346e+02,  1.2149e+02,\n",
      "         2.0659e+02, -9.4636e+01,  1.6529e+01,  1.2794e+01, -5.4253e+01,\n",
      "        -1.3649e+02, -1.5862e+02, -7.3204e+01, -1.0871e+02, -4.1358e+01,\n",
      "         8.7456e+01, -2.9850e+01, -8.2067e+01,  2.4762e+02,  1.2415e+01,\n",
      "        -7.2697e+01,  5.9712e+01,  1.4094e+02, -7.8753e+01,  1.2617e+02,\n",
      "         3.5442e+01,  8.0529e+01, -1.0942e+01,  7.1233e+01, -1.1599e+02,\n",
      "         2.1652e+02,  3.0977e+01,  6.8507e+01,  1.3191e+01,  5.9163e+01,\n",
      "         1.3397e+02, -3.6626e+01,  2.3008e+01, -1.4220e+02,  5.8329e-01,\n",
      "        -1.4965e+02, -1.8205e+02, -6.4395e+01,  5.9695e+01, -1.8939e+02,\n",
      "         5.7627e+01, -2.1915e+02, -5.5917e+01,  4.3368e+01,  3.0915e+01,\n",
      "        -9.1163e+01, -4.4373e+00, -5.8357e+00,  9.1568e+01, -1.9552e+02,\n",
      "         2.1007e+01, -7.5463e+01,  7.2307e+01, -9.2006e+00,  2.6992e+01,\n",
      "         1.2690e+00,  8.3888e+00, -1.7479e+01,  1.5024e+01, -6.7185e+01,\n",
      "         1.4481e+02,  1.2871e+02,  1.6893e+01, -1.7898e+02, -4.6050e+01,\n",
      "         2.1620e+01, -1.0760e+02,  2.5739e+01,  5.7169e+01, -1.2492e+02,\n",
      "        -4.5456e+01, -1.6947e+01,  4.3848e+01,  1.0129e+01,  3.4637e+01,\n",
      "        -2.3818e+01,  8.9449e+01,  1.0332e+02, -5.6504e+00, -8.8262e+01,\n",
      "         3.4179e+01, -7.0748e+01, -1.7006e+02,  4.8273e+01,  1.8326e+02,\n",
      "         2.2277e+00,  1.7535e+01, -5.3783e+01, -1.0287e+01,  4.3933e+01,\n",
      "         1.5707e+02,  1.3603e+02,  7.5559e+01,  1.1764e+02, -9.7769e+01,\n",
      "        -4.0892e+01, -1.7940e+02, -1.3885e+01,  1.1351e+01, -1.4667e+02,\n",
      "         1.3743e+02, -9.2407e+01,  1.2763e+01, -1.0243e+02, -7.8905e+01,\n",
      "        -1.0877e+02, -1.2797e+02, -4.1780e+01, -8.9174e+01,  1.2957e+02,\n",
      "        -7.1957e+01,  1.6239e+01, -2.8493e+01,  1.3522e+02,  1.5421e+02,\n",
      "         7.0057e+01, -8.3847e+00, -4.9592e+01,  2.4166e+01,  6.8451e+01,\n",
      "        -1.3618e+02,  7.8341e+01, -1.1202e+02,  1.3404e+02,  7.1588e+01,\n",
      "         4.9157e+01, -1.5083e+02, -1.4496e+02, -8.6805e+01,  6.9524e+01,\n",
      "         2.9417e+02, -1.3228e+02,  2.2890e-01,  6.0437e+01, -1.2902e+02,\n",
      "        -1.0426e+02, -1.1508e+02, -2.4152e+00,  8.7305e+01,  7.7152e+01,\n",
      "        -1.0408e+00, -1.2455e+01,  4.1178e+01, -3.5542e+01, -4.5809e+01,\n",
      "        -1.1790e+02,  2.2691e+01,  2.1474e+01,  7.0393e+01, -1.8289e+01,\n",
      "        -2.7772e+01,  7.2591e+01,  1.3314e+02, -1.6088e+01,  5.7614e+01,\n",
      "        -1.8747e+02, -1.5211e+02, -1.3113e+02,  1.6933e+02,  1.9349e+02,\n",
      "        -5.1933e+01, -9.0477e+01, -4.9108e+01, -7.6579e+01, -6.3715e+00,\n",
      "        -1.7283e+02, -5.0898e+01,  3.3325e+01, -6.0194e+01,  4.7828e+01,\n",
      "         2.1024e+02, -2.4052e+02,  1.9897e+02,  5.0753e+01, -1.3242e+01,\n",
      "        -1.8224e+02,  7.1022e+01,  6.2824e+00, -8.8873e+01, -6.5872e+01,\n",
      "         9.0114e+01,  1.0696e+01, -2.9880e+00,  7.0902e+01,  1.4177e+01,\n",
      "        -1.4713e+02,  3.0286e+00,  6.1018e+01, -2.4671e+01, -6.0039e+01,\n",
      "         5.9381e+01, -2.5793e+01, -1.3514e+01,  1.6240e+02,  1.0683e+02,\n",
      "         2.5118e+01, -3.3653e+00, -7.6659e+01, -8.3174e+01,  1.3612e+01,\n",
      "        -3.0426e+01, -1.2057e+02, -1.8280e+02, -1.1757e+02, -1.2252e+01,\n",
      "        -1.2704e+02,  4.3906e+00,  9.0742e+01,  4.0324e+01,  5.3241e+01,\n",
      "        -1.6623e+02,  3.8138e+01, -1.8856e+02, -4.8880e+00,  3.9070e+01,\n",
      "         5.1490e+01, -3.2868e+01, -1.7897e+02, -1.3118e+02,  9.2019e+01,\n",
      "        -1.9178e-01, -8.0295e+01,  1.3199e+02,  5.4177e+01,  4.9337e+01,\n",
      "         1.1109e+02, -2.6123e+00,  3.6298e+01,  9.6586e+01, -5.1970e+01,\n",
      "        -5.4230e+01,  2.4867e+00,  8.5790e+01, -3.9999e+01, -6.9046e+01,\n",
      "        -5.4643e+00,  8.7115e+01,  2.8124e+01, -8.7535e+01, -1.1195e+02,\n",
      "        -4.0315e+01, -9.4970e+01,  4.0934e+01, -8.6053e+01,  1.6214e+01,\n",
      "         1.2799e+02, -1.7399e+02, -7.5197e+01,  1.8794e+01, -9.9505e+01,\n",
      "         4.2731e+01,  5.8109e+01, -1.2685e+02,  2.4867e+01, -1.5257e+01,\n",
      "         1.1191e+01,  6.4339e+01,  3.9148e+01,  6.3982e+01, -2.3576e+01,\n",
      "        -2.2352e+01, -4.8584e+01, -4.6788e+01,  6.3370e+01, -8.7658e+01,\n",
      "         8.9640e+01, -1.2737e+02,  1.4029e+02])\n"
     ]
    }
   ],
   "source": [
    "# Compare output of forward pass of BfBertEmbeddings and BertEmbeddings on the text - they're equal!\n",
    "jax_input_ids = jnp.array(input_ids.numpy(), dtype=int)\n",
    "torch_embs.train(False)\n",
    "out_bf = bf_embs(input_ids=jax_input_ids)\n",
    "out_torch = torch_embs(input_ids=input_ids)\n",
    "# print(out_bf.val)\n",
    "# print(out_torch)\n",
    "assert(check_node_allclose_tensor(out_bf, out_torch))\n",
    "\n",
    "# Compare grad after backward pass\n",
    "torch_embs.train(True)\n",
    "out_torch.backward(gradient=torch.ones_like(out_torch))\n",
    "# out_bf.backprop()\n",
    "\n",
    "print(\"word_embeddings:\", bf_embs.word_embeddings.weight.grad, torch_embs.word_embeddings.weight.grad)\n",
    "print(\"position_embeddings:\", bf_embs.position_embeddings.weight.grad, torch_embs.position_embeddings.weight.grad)\n",
    "print(\"token_type_embeddings:\", bf_embs.token_type_embeddings.weight.grad, torch_embs.token_type_embeddings.weight.grad)\n",
    "print(\"LayerNorm:\", bf_embs.LayerNorm.weight.grad, torch_embs.LayerNorm.weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_bf.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('jax-hf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
