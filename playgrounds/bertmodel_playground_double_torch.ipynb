{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff0e20de6f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "from dataclasses import is_dataclass\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    "    BertSelfAttention,\n",
    "    BfBertSelfAttention,\n",
    "    BertSelfOutput,\n",
    "    BfBertSelfOutput,\n",
    "    BertAttention,\n",
    "    BfBertAttention,\n",
    "    BertLayer,\n",
    "    BfBertLayer,\n",
    "    BertEncoder,\n",
    "    BfBertEncoder,\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BfBaseModelOutputWithPastAndCrossAttentions,\n",
    "    BertModel,\n",
    "    BfBertModel,\n",
    ")\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from utils import check_bf_param_weights_match_torch, check_equivalent_class, check_dataclass_keys_match, check_model_outputs_allclose, check_bf_model_outputs_match_torch_outputs, check_bf_param_grads_allclose_torch\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Init torch and bf models\n",
    "BF_FROM_MODEL_ID = False\n",
    "TORCH_FROM_MODEL_ID = True\n",
    "# model_id = \"bert-base-uncased\"\n",
    "model_id = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"../../brunoflow/models/bert/config-tiny.json\")\n",
    "\n",
    "torch_model = BertModel.from_pretrained(model_id)\n",
    "torch_model2 = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish data\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_id)\n",
    "text = [\"hello I want to eat some [MASK] meat today. It's thanksgiving [MASK] all!\", \"yo hi what's up\"]\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Create torch and bf inputs to model\n",
    "input_ids_torch = tokens[\"input_ids\"]\n",
    "labels_torch = torch.ones_like(input_ids_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>\n",
      "CPU times: user 92.3 ms, sys: 0 ns, total: 92.3 ms\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_torch = torch_model(input_ids_torch)\n",
    "print(type(outputs_torch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertModel to file\n",
    "save_path = \"bertmodel_torch.pt\"\n",
    "torch.save(torch_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state dict for BertSelfAttention into BF and check weights, outputs, and backprop\n",
    "torch_model2.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check weights of BF model and Torch model match exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight embeddings.word_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.position_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.token_type_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.query.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.query.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.key.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.key.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.value.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.value.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.intermediate.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.intermediate.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.query.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.query.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.key.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.key.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.value.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.value.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.intermediate.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.intermediate.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight pooler.dense.weight for bf and torch are equal? True\n",
      "Value of param weight pooler.dense.bias for bf and torch are equal? True\n"
     ]
    }
   ],
   "source": [
    "# Check weights match\n",
    "from torch.nn import Module\n",
    "def check_torch_param_weights_match_torch(torch_module: Module, torch_module2: Module):\n",
    "    \"\"\"Used to verify the weights of the bf model and torch module are equal.\"\"\"\n",
    "    torch_params = {name: param for name, param in torch_module.named_parameters()}\n",
    "    torch_params2 = {name: param for name, param in torch_module2.named_parameters()}\n",
    "    assert set(torch_params.keys()) == set(\n",
    "        torch_params2.keys()\n",
    "    ), f\"BF and torch keys do not match: BF contains following extra keys {set(torch_params.keys()).difference(set(torch_params2.keys()))} and is missing keys {set(torch_params.keys()).difference(set(bf_params.keys()))}\"\n",
    "\n",
    "    for name in torch_params.keys():\n",
    "        print(\n",
    "            f\"Value of param weight {name} for bf and torch are equal? {torch.equal(torch_params[name], torch_params2[name])}\"\n",
    "        )\n",
    "        assert torch.equal(\n",
    "            torch_params[name], torch_params2[name]\n",
    "        ), f\"Value of param {name} for bf and torch are not equal.\"\n",
    "check_torch_param_weights_match_torch(torch_model, torch_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model output after forward pass matches for BF and Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output from forward passes match for bf and torch\n",
    "torch_model.train(False)\n",
    "torch_model2.train(False)\n",
    "outputs_torch = torch_model(input_ids_torch)\n",
    "outputs_torch2 = torch_model2(input_ids_torch)\n",
    "\n",
    "if isinstance(outputs_torch2, (list, tuple)) or is_dataclass(outputs_torch2):\n",
    "    assert len(outputs_torch2) == len(outputs_torch)\n",
    "    for i in range(len(outputs_torch2)):\n",
    "        out_bf, out_torch = outputs_torch2[i], outputs_torch[i]\n",
    "        assert torch.allclose(out_bf, out_torch, atol=1e-6)\n",
    "# elif is_dataclass(outputs_torch2):\n",
    "#     assert torch.allclose(outputs_torch2, outputs_torch, atol=1e-6)\n",
    "    # check_model_outputs_allclose(outputs_torch2, outputs_torch, print_stats=True, atol=1e-2)\n",
    "else:\n",
    "    assert torch.allclose(outputs_torch2, outputs_torch, atol=1e-6)\n",
    "    # check_bf_model_outputs_match_torch_outputs(outputs_torch2, outputs_torch, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check grad after backward pass matches for BF and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check grads equal before backward passes\n",
    "torch_model.train(True)\n",
    "torch_model2.train(True)\n",
    "\n",
    "def check_torch2_param_grads_allclose_torch(\n",
    "    torch_module: Module, torch_module2: Module, atol=1e-6\n",
    "):\n",
    "    \"\"\"Used to verify that grad after backward passes for bf and torch are close for all params in the network.\"\"\"\n",
    "    bf_params = {name: param for name, param in torch_module2.named_parameters()}\n",
    "    torch_params = {name: param for name, param in torch_module.named_parameters()}\n",
    "    assert set(bf_params.keys()) == set(\n",
    "        torch_params.keys()\n",
    "    ), f\"BF and torch keys do not match: BF contains following extra keys {set(bf_params.keys()).difference(set(torch_params.keys()))} and is missing keys {set(torch_params.keys()).difference(set(bf_params.keys()))}\"\n",
    "\n",
    "    not_allclose_params = []\n",
    "    for name in bf_params.keys():\n",
    "        if torch_params[name].grad is None:\n",
    "            assert bf_params[name].grad is None\n",
    "            # bf_grad_is_zero = jnp.array_equal(bf_params[name].grad, jnp.zeros_like(bf_params[name].grad))\n",
    "            # print(f\"No grad for param {name} for torch. BF grad is zero? {bf_params.grad is None}\")\n",
    "            # if not bf_grad_is_zero:\n",
    "            #     not_allclose_params.append(name)\n",
    "        else:\n",
    "            assert torch.allclose(torch_params[name].grad, bf_params[name].grad, atol=atol)\n",
    "            # is_allclose = jnp.allclose(bf_params[name].grad, torch_params[name].grad.numpy(), atol=atol)\n",
    "            # if print_output:\n",
    "            #     print(f\"Grad of param {name} for bf and torch are within {atol}? {is_allclose}\")\n",
    "            # if not is_allclose:\n",
    "            #     diff = jnp.abs(bf_params[name].grad - torch_params[name].grad.numpy())\n",
    "            #     diff_df = pd.DataFrame(diff)\n",
    "            #     not_allclose_params.append(name)\n",
    "            #     if print_stats:\n",
    "            #         print(f\"\\tStats on diff in grad for {name} between bf and torch: {diff_df.describe()}\")\n",
    "\n",
    "    # if use_assert:\n",
    "    #     assert not not_allclose_params, f\"Grad of params {not_allclose_params} for bf and torch are not within {atol}.\"\n",
    "\n",
    "\n",
    "check_torch2_param_grads_allclose_torch(torch_model2, torch_model, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 ms, sys: 379 ms, total: 401 ms\n",
      "Wall time: 864 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1664405705473/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Torch backward pass\n",
    "torch_model.train(True)\n",
    "\n",
    "if isinstance(outputs_torch, (list, tuple)):\n",
    "    assert len(outputs_torch) == len(outputs_torch2)\n",
    "    backprop_node_torch = outputs_torch[0]\n",
    "elif is_dataclass(outputs_torch):\n",
    "    backprop_node_torch = outputs_torch.last_hidden_state\n",
    "else:\n",
    "    backprop_node_torch = outputs_torch\n",
    "    \n",
    "backprop_node_torch.backward(gradient=torch.ones_like(backprop_node_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.43 ms, sys: 25.6 ms, total: 30 ms\n",
      "Wall time: 4.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Torch2 backward pass\n",
    "torch_model2.train(True)\n",
    "\n",
    "if isinstance(outputs_torch2, (list, tuple)):\n",
    "    assert len(outputs_torch) == len(outputs_torch2)\n",
    "    backprop_node_torch2 = outputs_torch2[0]\n",
    "elif is_dataclass(outputs_torch2):\n",
    "    backprop_node_torch2 = outputs_torch2.last_hidden_state\n",
    "else:\n",
    "    backprop_node_torch2 = outputs_torch2\n",
    "    \n",
    "backprop_node_torch2.backward(gradient=torch.ones_like(backprop_node_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the actual check\n",
    "check_torch2_param_grads_allclose_torch(torch_model, torch_model2, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch_model.state_dict()) == str(torch_model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = torch.abs(dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"].grad - dict(torch_model2.named_parameters())[\"embeddings.word_embeddings.weight\"].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(torch.argmax(diff, axis=0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mmax\u001b[39;49m(diff[diff\u001b[39m.\u001b[39;49mnonzero()]), torch\u001b[39m.\u001b[39margmax(diff[diff\u001b[39m.\u001b[39mnonzero()]), diff[diff\u001b[39m.\u001b[39mnonzero()][torch\u001b[39m.\u001b[39margmax(diff[diff\u001b[39m.\u001b[39mnonzero()])]\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "max(diff[diff.nonzero()]), torch.argmax(diff[diff.nonzero()]), diff[diff.nonzero()][torch.argmax(diff[diff.nonzero()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   101,   101, ..., 15060, 15060, 15060],\n",
       "       [    0,     1,     2, ...,   125,   126,   127]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(diff.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0074, -0.0071, -0.0071,  ..., -0.0098, -0.0134,  0.0195],\n",
       "        [ 0.0149, -0.0253,  0.0369,  ...,  0.0013,  0.0134, -0.0148],\n",
       "        ...,\n",
       "        [-0.0044, -0.0172, -0.0067,  ..., -0.0144, -0.0035,  0.0195],\n",
       "        [-0.0062, -0.0042,  0.0309,  ...,  0.0092, -0.0042,  0.0180],\n",
       "        [ 0.0138,  0.0062, -0.0471,  ...,  0.0233,  0.0133, -0.0152]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2816, 2, 128]), torch.Size([2816, 2]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"]\n",
    "weight_grads = weight.grad\n",
    "weight_grads[weight_grads.nonzero()[0]], weight_grads.nonzero()[0]\n",
    "weight_grads[weight_grads.nonzero()].shape, weight_grads.nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0074, -0.0071, -0.0071,  ..., -0.0098, -0.0134,  0.0195],\n",
       "         [ 0.0149, -0.0253,  0.0369,  ...,  0.0013,  0.0134, -0.0148],\n",
       "         ...,\n",
       "         [-0.0044, -0.0172, -0.0067,  ..., -0.0144, -0.0035,  0.0195],\n",
       "         [-0.0062, -0.0042,  0.0309,  ...,  0.0092, -0.0042,  0.0180],\n",
       "         [ 0.0138,  0.0062, -0.0471,  ...,  0.0233,  0.0133, -0.0152]],\n",
       "        requires_grad=True),\n",
       " DeviceArray([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "                0.        ,  0.        ],\n",
       "              [-0.00743891, -0.00712189, -0.00712206, ..., -0.00981665,\n",
       "               -0.01344507,  0.01948544],\n",
       "              [ 0.01491467, -0.02525557,  0.03694721, ...,  0.00127098,\n",
       "                0.01342611, -0.01483316],\n",
       "              ...,\n",
       "              [-0.00436839, -0.01722462, -0.00671953, ..., -0.01438164,\n",
       "               -0.00348806,  0.01950711],\n",
       "              [-0.00620748, -0.00421648,  0.03085984, ...,  0.00919393,\n",
       "               -0.00424885,  0.01799364],\n",
       "              [ 0.01384658,  0.00621966, -0.04711508, ...,  0.02332082,\n",
       "                0.01329507, -0.01516467]], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, dict(bf_model.named_parameters())[\"embeddings.word_embeddings.weight\"].val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
