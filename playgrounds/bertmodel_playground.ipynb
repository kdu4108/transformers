{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feba2cce6f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "from dataclasses import is_dataclass\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    "    BertSelfAttention,\n",
    "    BfBertSelfAttention,\n",
    "    BertSelfOutput,\n",
    "    BfBertSelfOutput,\n",
    "    BertAttention,\n",
    "    BfBertAttention,\n",
    "    BertLayer,\n",
    "    BfBertLayer,\n",
    "    BertEncoder,\n",
    "    BfBertEncoder,\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BfBaseModelOutputWithPastAndCrossAttentions,\n",
    "    BertModel,\n",
    "    BfBertModel,\n",
    ")\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from utils import check_bf_param_weights_match_torch, check_equivalent_class, check_dataclass_keys_match, check_model_outputs_allclose, check_bf_model_outputs_match_torch_outputs, check_bf_param_grads_allclose_torch\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2023-01-05 00:13:21.320889: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: TODO(KD) - when this is used, write some tests for this!\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n",
      "WARNING: we don't actually initialize weights here! If we ever need to actually train we can properly implement this.\n"
     ]
    }
   ],
   "source": [
    "# Init torch and bf models\n",
    "BF_FROM_MODEL_ID = False ### NOTE: BECAUSE THIS IS SUPER HACKY THIS SOMEWHAT DOES NOT WORK WHEN SET TO TRUE. FROM_PRETRAINED FOR BRUNOFLOW IS PROBABLY SOMEWHAT BROKEN, BUT AT LEAST THIS IS A WORKAROUND. Also it looks like the errors are only bounded by 0.01 :/.\n",
    "TORCH_FROM_MODEL_ID = True\n",
    "# model_id = \"bert-base-uncased\"\n",
    "model_id = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"../../brunoflow/models/bert/config-tiny.json\")\n",
    "\n",
    "if TORCH_FROM_MODEL_ID:\n",
    "    torch_model = BertModel.from_pretrained(model_id)\n",
    "else:\n",
    "    torch_model = BertModel(config)\n",
    "if BF_FROM_MODEL_ID:\n",
    "    bf_model = BfBertModel.from_pretrained(model_id)\n",
    "else:\n",
    "    bf_model = BfBertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish data\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_id)\n",
    "# text = [\"hello hello hello there\"]#, \"yo hi what's up\", \"bleh this sucks\"]\n",
    "text = [\"hello I want to eat some [MASK] meat today. It's thanksgiving [MASK] all!\", \"yo uo hi what's up\"] #, \"bleh this sucks\"]\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Create torch and bf inputs to model\n",
    "input_ids_torch = tokens[\"input_ids\"]\n",
    "labels_torch = torch.ones_like(input_ids_torch)\n",
    "\n",
    "input_ids_bf = jnp.array(input_ids_torch.numpy())\n",
    "labels_bf = jnp.array(labels_torch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>\n",
      "CPU times: user 89.4 ms, sys: 0 ns, total: 89.4 ms\n",
      "Wall time: 13.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_torch = torch_model(input_ids_torch)\n",
    "print(type(outputs_torch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_bf_outputs.BfBaseModelOutputWithPoolingAndCrossAttentions'>\n",
      "CPU times: user 1 s, sys: 14.4 ms, total: 1.01 s\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_bf = bf_model(input_ids_bf)\n",
    "print(type(outputs_bf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that forward pass for bf works and matches output shape with torch\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    # Handle case where outputs is a tuple/list and not just a single item\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i] \n",
    "        assert(out_torch.shape == out_bf.shape)\n",
    "elif is_dataclass(outputs_bf):\n",
    "    check_equivalent_class(outputs_bf, outputs_torch)\n",
    "    check_dataclass_keys_match(outputs_bf, outputs_torch)\n",
    "else:\n",
    "    assert(outputs_torch.shape == outputs_bf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertModel to file\n",
    "save_path = \"bertmodel_torch.pt\"\n",
    "torch.save(torch_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load state dict for BertModel into BF and check weights, outputs, and backprop\n",
    "if not BF_FROM_MODEL_ID:\n",
    "    bf_model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check weights of BF model and Torch model match exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not detaching params for module BfBertModel when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertEmbeddings when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Embedding when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Embedding when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Embedding when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module LayerNorm when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Dropout when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertEncoder when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module ModuleList when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertLayer when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertAttention when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertSelfAttention when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Dropout when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertSelfOutput when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module LayerNorm when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Dropout when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertIntermediate when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertOutput when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module LayerNorm when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Dropout when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertLayer when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertAttention when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertSelfAttention when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Dropout when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertSelfOutput when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module LayerNorm when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Dropout when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertIntermediate when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertOutput when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module LayerNorm when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Dropout when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module BfBertPooler when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Linear when saving state dict bc BF doesn't support that.\n",
      "WARNING: not detaching params for module Tanh when saving state dict bc BF doesn't support that.\n",
      "Models match perfectly! :)\n"
     ]
    }
   ],
   "source": [
    "def compare_models(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if check_node_equals_tensor(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                print('Mismatch found at', key_item_1[0])\n",
    "            else:\n",
    "                raise Exception\n",
    "    if models_differ == 0:\n",
    "        print('Models match perfectly! :)')\n",
    "\n",
    "compare_models(bf_model, torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight embeddings.word_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.position_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.token_type_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight embeddings.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.query.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.query.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.key.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.key.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.value.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.self.value.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.attention.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.intermediate.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.intermediate.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.0.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.query.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.query.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.key.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.key.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.value.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.self.value.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.attention.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.intermediate.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.intermediate.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight encoder.layer.1.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight pooler.dense.weight for bf and torch are equal? True\n",
      "Value of param weight pooler.dense.bias for bf and torch are equal? True\n"
     ]
    }
   ],
   "source": [
    "# Check weights match\n",
    "check_bf_param_weights_match_torch(bf_model, torch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model output after forward pass matches for BF and Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.dropout 0.1\n",
      "embeddings.dropout 0\n",
      "encoder.layer.0.attention.self.dropout 0.1\n",
      "encoder.layer.0.attention.self.dropout 0\n",
      "encoder.layer.0.attention.output.dropout 0.1\n",
      "encoder.layer.0.attention.output.dropout 0\n",
      "encoder.layer.0.output.dropout 0.1\n",
      "encoder.layer.0.output.dropout 0\n",
      "encoder.layer.1.attention.self.dropout 0.1\n",
      "encoder.layer.1.attention.self.dropout 0\n",
      "encoder.layer.1.attention.output.dropout 0.1\n",
      "encoder.layer.1.attention.output.dropout 0\n",
      "encoder.layer.1.output.dropout 0.1\n",
      "encoder.layer.1.output.dropout 0\n"
     ]
    }
   ],
   "source": [
    "# Set all dropouts to 0\n",
    "for name, module in torch_model.named_modules():\n",
    "    if module._get_name() == \"Dropout\":\n",
    "        print(name, module.p)\n",
    "        module.p = 0\n",
    "        print(name, module.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking diff between BF and torch for last_hidden_state:\n",
      "Output of bf and torch are within 0.01? True\n",
      "\tStats on diff in outputs between bf and torch:                   0\n",
      "count  4.864000e+03\n",
      "mean   5.016467e-07\n",
      "std    4.475989e-07\n",
      "min    3.336587e-11\n",
      "25%    1.814181e-07\n",
      "50%    3.889932e-07\n",
      "75%    6.923858e-07\n",
      "max    4.264745e-06\n",
      "Checking diff between BF and torch for pooler_output:\n",
      "Output of bf and torch are within 0.01? True\n",
      "\tStats on diff in outputs between bf and torch:                   0\n",
      "count  2.560000e+02\n",
      "mean   1.013631e-07\n",
      "std    1.682405e-07\n",
      "min    1.373492e-10\n",
      "25%    1.481915e-08\n",
      "50%    3.548915e-08\n",
      "75%    9.879269e-08\n",
      "max    1.147149e-06\n"
     ]
    }
   ],
   "source": [
    "# Check output from forward passes match for bf and torch\n",
    "torch_model.train(False)\n",
    "bf_model.train(False)\n",
    "outputs_bf = bf_model(input_ids_bf)\n",
    "outputs_torch = torch_model(input_ids_torch)\n",
    "\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i]\n",
    "        check_bf_model_outputs_match_torch_outputs(out_bf, out_torch, atol=1e-6)\n",
    "elif is_dataclass(outputs_bf):\n",
    "    check_model_outputs_allclose(outputs_bf, outputs_torch, print_stats=True, atol=1e-2)\n",
    "else:\n",
    "    check_bf_model_outputs_match_torch_outputs(outputs_bf, outputs_torch, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check grad after backward pass matches for BF and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No grad for param embeddings.word_embeddings.weight for torch. BF grad is zero? True\n",
      "No grad for param embeddings.position_embeddings.weight for torch. BF grad is zero? True\n",
      "No grad for param embeddings.token_type_embeddings.weight for torch. BF grad is zero? True\n",
      "No grad for param embeddings.LayerNorm.weight for torch. BF grad is zero? True\n",
      "No grad for param embeddings.LayerNorm.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.self.query.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.self.query.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.self.key.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.self.key.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.self.value.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.self.value.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.output.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.output.dense.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.output.LayerNorm.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.attention.output.LayerNorm.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.intermediate.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.intermediate.dense.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.output.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.output.dense.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.output.LayerNorm.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.0.output.LayerNorm.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.self.query.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.self.query.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.self.key.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.self.key.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.self.value.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.self.value.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.output.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.output.dense.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.output.LayerNorm.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.attention.output.LayerNorm.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.intermediate.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.intermediate.dense.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.output.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.output.dense.bias for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.output.LayerNorm.weight for torch. BF grad is zero? True\n",
      "No grad for param encoder.layer.1.output.LayerNorm.bias for torch. BF grad is zero? True\n",
      "No grad for param pooler.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param pooler.dense.bias for torch. BF grad is zero? True\n"
     ]
    }
   ],
   "source": [
    "# Check grads equal before backward passes\n",
    "torch_model.train(True)\n",
    "bf_model.train(True)\n",
    "check_bf_param_grads_allclose_torch(bf_model, torch_model, atol=1e-2, print_output=False, print_stats=False, use_assert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 2.49 ms, total: 16.8 ms\n",
      "Wall time: 7.77 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1664405705473/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Torch backward pass\n",
    "torch_model.train(True)\n",
    "\n",
    "if isinstance(outputs_torch, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    backprop_node_torch = outputs_torch[0]\n",
    "elif is_dataclass(outputs_torch):\n",
    "    backprop_node_torch = outputs_torch.last_hidden_state\n",
    "else:\n",
    "    backprop_node_torch = outputs_torch\n",
    "    \n",
    "backprop_node_torch.backward(gradient=torch.ones_like(backprop_node_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.51 s, sys: 5.61 s, total: 15.1 s\n",
      "Wall time: 7.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int64. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int64. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# BF backward pass\n",
    "bf_model.train(True)\n",
    "\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    backprop_node = outputs_bf[0]\n",
    "elif is_dataclass(outputs_torch):\n",
    "    backprop_node = outputs_bf.last_hidden_state\n",
    "else:\n",
    "    backprop_node = outputs_bf\n",
    "    \n",
    "backprop_node.backprop(values_to_compute=(\"grad\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad of param embeddings.word_embeddings.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param embeddings.position_embeddings.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param embeddings.token_type_embeddings.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param embeddings.LayerNorm.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param embeddings.LayerNorm.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.self.query.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.self.query.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.self.key.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.self.key.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.self.value.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.self.value.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.output.dense.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.output.dense.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.output.LayerNorm.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.attention.output.LayerNorm.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.intermediate.dense.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.intermediate.dense.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.output.dense.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.output.dense.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.output.LayerNorm.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.0.output.LayerNorm.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.self.query.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.self.query.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.self.key.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.self.key.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.self.value.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.self.value.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.output.dense.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.output.dense.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.output.LayerNorm.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.attention.output.LayerNorm.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.intermediate.dense.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.intermediate.dense.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.output.dense.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.output.dense.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.output.LayerNorm.weight for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "Grad of param encoder.layer.1.output.LayerNorm.bias for bf and torch are within rtol=0.0001, atol=1e-05? True\n",
      "No grad for param pooler.dense.weight for torch. BF grad is zero? True\n",
      "No grad for param pooler.dense.bias for torch. BF grad is zero? True\n"
     ]
    }
   ],
   "source": [
    "# Run the actual check\n",
    "check_bf_param_grads_allclose_torch(bf_model, torch_model, rtol=1e-4, atol=1e-5, print_output=True, print_stats=True, use_assert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous extra code for testing/debugging the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in torch_model.children():\n",
    "    if child._get_name() == \"BertEmbeddings\":\n",
    "        break\n",
    "for name, grandchild in child.named_modules():\n",
    "    if name == \"word_embeddings\":\n",
    "        break\n",
    "\n",
    "torch_emb = child\n",
    "torch_word_emb = grandchild\n",
    "\n",
    "for child in bf_model.children():\n",
    "    if child._get_name() == \"BfBertEmbeddings\":\n",
    "        break\n",
    "for name, grandchild in child.named_modules():\n",
    "    if name == \"word_embeddings\":\n",
    "        break\n",
    "    \n",
    "bf_emb = child\n",
    "bf_word_emb = grandchild\n",
    "\n",
    "# print(torch_emb)\n",
    "# print(bf_emb)\n",
    "# print(torch_word_emb)\n",
    "# print(bf_word_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight word_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight position_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight token_type_embeddings.weight for bf and torch are equal? True\n",
      "Value of param weight LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight LayerNorm.bias for bf and torch are equal? True\n",
      "Output of bf and torch are within 0.001? True\n",
      "torch grad at [(102, 0)]: tensor(26.4956)\n",
      "bf grad at [(102, 0)]: 26.495648581566883\n",
      "torch val at [(102, 0)]: tensor(-0.0756, grad_fn=<SelectBackward0>)\n",
      "bf val at [(102, 0)]: -0.07556523\n",
      "\n",
      "torch grad at [(1055, 0)]: tensor(20.6873)\n",
      "bf grad at [(1055, 0)]: 20.68725014962451\n",
      "torch val at [(1055, 0)]: tensor(-0.0034, grad_fn=<SelectBackward0>)\n",
      "bf val at [(1055, 0)]: -0.0034130977\n",
      "\n",
      "torch grad at [(1005, 43)]: tensor(20.6858)\n",
      "bf grad at [(1005, 43)]: 20.685824248006\n",
      "torch val at [(1005, 43)]: tensor(-0.0300, grad_fn=<SelectBackward0>)\n",
      "bf val at [(1005, 43)]: -0.030014599\n",
      "\n",
      "torch grad at [(102, 74)]: tensor(20.4638)\n",
      "bf grad at [(102, 74)]: 20.46383095139027\n",
      "torch val at [(102, 74)]: tensor(0.0280, grad_fn=<SelectBackward0>)\n",
      "bf val at [(102, 74)]: 0.027993163\n",
      "\n",
      "torch grad at [(1005, 0)]: tensor(19.4510)\n",
      "bf grad at [(1005, 0)]: 19.450998881344564\n",
      "torch val at [(1005, 0)]: tensor(-0.0172, grad_fn=<SelectBackward0>)\n",
      "bf val at [(1005, 0)]: -0.01724221\n",
      "\n",
      "Grad of param word_embeddings.weight for bf and torch are within rtol=0.001, atol=0.01? True\n",
      "Grad of param position_embeddings.weight for bf and torch are within rtol=0.001, atol=0.01? True\n",
      "Grad of param token_type_embeddings.weight for bf and torch are within rtol=0.001, atol=0.01? True\n",
      "Grad of param LayerNorm.weight for bf and torch are within rtol=0.001, atol=0.01? True\n",
      "Grad of param LayerNorm.bias for bf and torch are within rtol=0.001, atol=0.01? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int64. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n"
     ]
    }
   ],
   "source": [
    "check_bf_param_weights_match_torch(bf_emb, torch_emb)\n",
    "out_emb_bf = bf_emb(input_ids_bf)\n",
    "out_emb_torch = torch_emb(input_ids_torch)\n",
    "check_bf_model_outputs_match_torch_outputs(out_emb_bf, out_emb_torch, atol=1e-3)\n",
    "out_emb_bf.backprop(values_to_compute=(\"grad\",))\n",
    "out_emb_torch.backward(gradient=torch.ones_like(out_emb_torch))\n",
    "\n",
    "topk = torch.topk(dict(torch_emb.named_parameters())[\"word_embeddings.weight\"].grad.flatten(), 5).indices\n",
    "dict(torch_emb.named_parameters())[\"word_embeddings.weight\"].reshape(-1)[13056]\n",
    "\n",
    "for k in topk:\n",
    "    k = int(k)\n",
    "    print(f\"torch grad at [{k // 128, k % 128}]:\", dict(torch_emb.named_parameters())[\"word_embeddings.weight\"].grad[k // 128, k % 128])\n",
    "    print(f\"bf grad at [{k // 128, k % 128}]:\", dict(bf_emb.named_parameters())[\"word_embeddings.weight\"].grad[k // 128, k % 128])\n",
    "    print(f\"torch val at [{k // 128, k % 128}]:\", dict(torch_emb.named_parameters())[\"word_embeddings.weight\"][k // 128, k % 128])\n",
    "    print(f\"bf val at [{k // 128, k % 128}]:\", dict(bf_emb.named_parameters())[\"word_embeddings.weight\"].val[k // 128, k % 128])\n",
    "    print()\n",
    "\n",
    "check_bf_param_grads_allclose_torch(bf_emb, torch_emb, atol=1e-2, print_output=True, print_stats=False, use_assert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight weight for bf and torch are equal? True\n",
      "Output of bf and torch are within 1e-06? True\n",
      "torch grad at [(101, 2)]: tensor(2.)\n",
      "bf grad at [(101, 2)]: 2.0\n",
      "\n",
      "torch grad at [(101, 1)]: tensor(2.)\n",
      "bf grad at [(101, 1)]: 2.0\n",
      "\n",
      "torch grad at [(101, 3)]: tensor(2.)\n",
      "bf grad at [(101, 3)]: 2.0\n",
      "\n",
      "torch grad at [(101, 4)]: tensor(2.)\n",
      "bf grad at [(101, 4)]: 2.0\n",
      "\n",
      "torch grad at [(101, 0)]: tensor(2.)\n",
      "bf grad at [(101, 0)]: 2.0\n",
      "\n",
      "Max torch word emb grad: tensor(2.)\n",
      "Max bf_word_emb grad: 2.0\n",
      "Grad of param weight for bf and torch are within rtol=0.001, atol=0.01? True\n"
     ]
    }
   ],
   "source": [
    "torch_word_emb.zero_grad()\n",
    "bf_word_emb.zero_grad()\n",
    "\n",
    "check_bf_param_weights_match_torch(bf_word_emb, torch_word_emb)\n",
    "out_emb_bf = bf_word_emb(input_ids_bf)\n",
    "out_emb_torch = torch_word_emb(input_ids_torch)\n",
    "check_bf_model_outputs_match_torch_outputs(out_emb_bf, out_emb_torch, atol=1e-6)\n",
    "out_emb_bf.backprop(values_to_compute=(\"grad\",))\n",
    "out_emb_torch.backward(gradient=torch.ones_like(out_emb_torch))\n",
    "\n",
    "topk = torch.topk(dict(torch_word_emb.named_parameters())[\"weight\"].grad.flatten(), 5).indices\n",
    "\n",
    "for k in topk:\n",
    "    k = int(k)\n",
    "    print(f\"torch grad at [{k // 128, k % 128}]:\", dict(torch_word_emb.named_parameters())[\"weight\"].grad[k // 128, k % 128])\n",
    "    print(f\"bf grad at [{k // 128, k % 128}]:\", dict(bf_word_emb.named_parameters())[\"weight\"].grad[k // 128, k % 128])\n",
    "    print()\n",
    "\n",
    "print(\"Max torch word emb grad:\", torch_word_emb.weight.grad.max())\n",
    "print(\"Max bf_word_emb grad:\", bf_word_emb.weight.grad.max())\n",
    "check_bf_param_grads_allclose_torch(bf_word_emb, torch_word_emb, atol=1e-2, print_output=True, print_stats=False, use_assert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check that when the embedding is saved and then loaded by torch that the grads are equal\n",
    "word_emb_save_path = \"bertmodel_torch_word_emb.pt\"\n",
    "torch.save(torch_word_emb.state_dict(), word_emb_save_path)\n",
    "torch_word_emb_loaded = torch.nn.Embedding(num_embeddings=torch_word_emb.num_embeddings, embedding_dim=torch_word_emb.embedding_dim, padding_idx=torch_word_emb.padding_idx)\n",
    "torch_word_emb_loaded.load_state_dict(torch.load(word_emb_save_path))\n",
    "\n",
    "# Check state_dicts are same\n",
    "str(torch_word_emb.state_dict()) == str(torch_word_emb_loaded.state_dict())\n",
    "torch_word_emb.zero_grad()\n",
    "torch_word_emb_loaded.zero_grad()\n",
    "\n",
    "# Check outputs are same\n",
    "out_emb_torch = torch_word_emb(input_ids_torch)\n",
    "out_emb_torch_loaded = torch_word_emb_loaded(input_ids_torch)\n",
    "assert torch.equal(out_emb_torch, out_emb_torch_loaded)\n",
    "\n",
    "# check grads are the same after backprop\n",
    "out_emb_torch.backward(gradient=torch.ones_like(out_emb_torch))\n",
    "out_emb_torch_loaded.backward(gradient=torch.ones_like(out_emb_torch_loaded))\n",
    "\n",
    "def check_torch2_param_grads_allclose_torch(\n",
    "    torch_module, torch_module2, atol=1e-6\n",
    "):\n",
    "    \"\"\"Used to verify that grad after backward passes for bf and torch are close for all params in the network.\"\"\"\n",
    "    bf_params = {name: param for name, param in torch_module2.named_parameters()}\n",
    "    torch_params = {name: param for name, param in torch_module.named_parameters()}\n",
    "    assert set(bf_params.keys()) == set(\n",
    "        torch_params.keys()\n",
    "    ), f\"BF and torch keys do not match: BF contains following extra keys {set(bf_params.keys()).difference(set(torch_params.keys()))} and is missing keys {set(torch_params.keys()).difference(set(bf_params.keys()))}\"\n",
    "\n",
    "    not_allclose_params = []\n",
    "    for name in bf_params.keys():\n",
    "        if torch_params[name].grad is None:\n",
    "            assert bf_params[name].grad is None\n",
    "        else:\n",
    "            assert torch.allclose(torch_params[name].grad, bf_params[name].grad, atol=atol)\n",
    "\n",
    "\n",
    "check_torch2_param_grads_allclose_torch(torch_word_emb, torch_word_emb_loaded, atol=1e-6)\n",
    "\n",
    "torch_word_emb_loaded.weight.grad.max()\n",
    "torch_word_emb.weight.grad.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight weight for bf and torch are equal? True\n",
      "Output of bf and torch are within 1e-06? True\n",
      "Max torch word emb grad: tensor(2.)\n",
      "Max bf_word_emb grad: 2.0\n",
      "Grad of param weight for bf and torch are within rtol=0.001, atol=0.01? True\n"
     ]
    }
   ],
   "source": [
    "### Check that when the embedding is saved by torch and then loaded by bf that the grads are equal\n",
    "from brunoflow.net import Embedding\n",
    "bf_word_emb_loaded = Embedding(num_embeddings=torch_word_emb.num_embeddings, embedding_dim=torch_word_emb.embedding_dim, padding_idx=torch_word_emb.padding_idx)\n",
    "bf_word_emb_loaded.load_state_dict(torch.load(word_emb_save_path))\n",
    "\n",
    "torch_word_emb_loaded.zero_grad()\n",
    "bf_word_emb_loaded.zero_grad()\n",
    "\n",
    "# Check weights\n",
    "check_bf_param_weights_match_torch(bf_word_emb_loaded, torch_word_emb_loaded)\n",
    "\n",
    "# Check outputs\n",
    "out_emb_bf = bf_word_emb_loaded(input_ids_bf)\n",
    "out_emb_torch = torch_word_emb_loaded(input_ids_torch)\n",
    "check_bf_model_outputs_match_torch_outputs(out_emb_bf, out_emb_torch, atol=1e-6)\n",
    "\n",
    "# Check grads\n",
    "out_emb_bf.backprop(values_to_compute=(\"grad\",))\n",
    "out_emb_torch.backward(gradient=torch.ones_like(out_emb_torch))\n",
    "\n",
    "print(\"Max torch word emb grad:\", torch_word_emb_loaded.weight.grad.max())\n",
    "print(\"Max bf_word_emb grad:\", bf_word_emb_loaded.weight.grad.max())\n",
    "\n",
    "check_bf_param_grads_allclose_torch(bf_word_emb_loaded, torch_word_emb_loaded, atol=1e-2, print_output=True, print_stats=False, use_assert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'training': True,\n",
       "  '_parameters': OrderedDict([('weight',\n",
       "                Parameter containing:\n",
       "                tensor([[-4.1018e-03, -3.0695e-02, -3.5295e-03,  ...,  1.8925e-02,\n",
       "                          3.7396e-03, -2.9233e-03],\n",
       "                        [-4.2748e-04, -3.6929e-02, -1.7168e-02,  ...,  2.9314e-02,\n",
       "                         -1.0398e-02,  2.6772e-02],\n",
       "                        [ 5.9418e-03,  4.2119e-03, -1.9566e-02,  ...,  1.6799e-02,\n",
       "                         -2.7802e-02, -6.9017e-03],\n",
       "                        ...,\n",
       "                        [ 3.5573e-02, -1.5891e-02,  4.9951e-03,  ...,  5.4071e-03,\n",
       "                         -1.1270e-02, -6.9528e-05],\n",
       "                        [-8.7018e-03, -2.2516e-02,  3.1993e-03,  ...,  2.7591e-02,\n",
       "                         -1.9554e-02,  2.4023e-03],\n",
       "                        [-7.8904e-02, -7.5407e-02, -4.6660e-03,  ..., -5.3340e-03,\n",
       "                         -4.4993e-02,  5.9842e-02]], requires_grad=True))]),\n",
       "  '_buffers': OrderedDict(),\n",
       "  '_non_persistent_buffers_set': set(),\n",
       "  '_backward_hooks': OrderedDict(),\n",
       "  '_is_full_backward_hook': None,\n",
       "  '_forward_hooks': OrderedDict(),\n",
       "  '_forward_pre_hooks': OrderedDict(),\n",
       "  '_state_dict_hooks': OrderedDict(),\n",
       "  '_load_state_dict_pre_hooks': OrderedDict(),\n",
       "  '_load_state_dict_post_hooks': OrderedDict(),\n",
       "  '_modules': OrderedDict(),\n",
       "  'num_embeddings': 30522,\n",
       "  'embedding_dim': 128,\n",
       "  'padding_idx': 0,\n",
       "  'max_norm': None,\n",
       "  'norm_type': 2.0,\n",
       "  'scale_grad_by_freq': False,\n",
       "  'sparse': False},\n",
       " {'training': True,\n",
       "  '_modules': OrderedDict(),\n",
       "  '_parameters': OrderedDict([('weight',\n",
       "                node(name: emb weights (30522, 128), val: [[-4.1018268e-03 -3.0694773e-02 -3.5295275e-03 ...  1.8925212e-02\n",
       "                   3.7396429e-03 -2.9232893e-03]\n",
       "                 [-4.2748044e-04 -3.6928687e-02 -1.7167933e-02 ...  2.9313693e-02\n",
       "                  -1.0397688e-02  2.6771577e-02]\n",
       "                 [ 5.9417770e-03  4.2118742e-03 -1.9566311e-02 ...  1.6798709e-02\n",
       "                  -2.7802430e-02 -6.9016502e-03]\n",
       "                 ...\n",
       "                 [ 3.5573229e-02 -1.5890833e-02  4.9951361e-03 ...  5.4070782e-03\n",
       "                  -1.1269928e-02 -6.9528171e-05]\n",
       "                 [-8.7017640e-03 -2.2515964e-02  3.1992516e-03 ...  2.7591001e-02\n",
       "                  -1.9553846e-02  2.4022695e-03]\n",
       "                 [-7.8904152e-02 -7.5407349e-02 -4.6659894e-03 ... -5.3339875e-03\n",
       "                  -4.4993456e-02  5.9841771e-02]], grad: [[0. 0. 0. ... 0. 0. 0.]\n",
       "                 [0. 0. 0. ... 0. 0. 0.]\n",
       "                 [0. 0. 0. ... 0. 0. 0.]\n",
       "                 ...\n",
       "                 [0. 0. 0. ... 0. 0. 0.]\n",
       "                 [0. 0. 0. ... 0. 0. 0.]\n",
       "                 [0. 0. 0. ... 0. 0. 0.]]))]),\n",
       "  '_buffers': OrderedDict(),\n",
       "  '_non_persistent_buffers_set': set(),\n",
       "  'num_embeddings': 30522,\n",
       "  'embedding_dim': 128,\n",
       "  'padding_idx': 0,\n",
       "  'name': 'Embedding Layer (30522, 128)'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(torch_word_emb), vars(bf_word_emb)\n",
    "# num_embeddings: int\n",
    "#     embedding_dim: int\n",
    "#     padding_idx: Optional[int]\n",
    "#     max_norm: Optional[float]\n",
    "#     norm_type: float\n",
    "#     scale_grad_by_freq: bool\n",
    "#     weight: Tensor\n",
    "#     sparse: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch grad at [(101, 2)]: tensor(2.)\n",
      "bf grad at [(101, 2)]: 2.0\n",
      "torch val at [(101, 2)]: tensor(-0.5026, grad_fn=<SelectBackward0>)\n",
      "bf val at [(101, 2)]: -0.5025546\n",
      "\n",
      "torch grad at [(101, 1)]: tensor(2.)\n",
      "bf grad at [(101, 1)]: 2.0\n",
      "torch val at [(101, 1)]: tensor(-0.0182, grad_fn=<SelectBackward0>)\n",
      "bf val at [(101, 1)]: -0.01819513\n",
      "\n",
      "torch grad at [(101, 3)]: tensor(2.)\n",
      "bf grad at [(101, 3)]: 2.0\n",
      "torch val at [(101, 3)]: tensor(-0.0100, grad_fn=<SelectBackward0>)\n",
      "bf val at [(101, 3)]: -0.010009427\n",
      "\n",
      "torch grad at [(101, 4)]: tensor(2.)\n",
      "bf grad at [(101, 4)]: 2.0\n",
      "torch val at [(101, 4)]: tensor(0.0039, grad_fn=<SelectBackward0>)\n",
      "bf val at [(101, 4)]: 0.0039283177\n",
      "\n",
      "torch grad at [(101, 0)]: tensor(2.)\n",
      "bf grad at [(101, 0)]: 2.0\n",
      "torch val at [(101, 0)]: tensor(0.0177, grad_fn=<SelectBackward0>)\n",
      "bf val at [(101, 0)]: 0.017665198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topk = torch.topk(dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"].grad.flatten(), 5).indices\n",
    "dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"].reshape(-1)[13056]\n",
    "\n",
    "for k in topk:\n",
    "    k = int(k)\n",
    "    print(f\"torch grad at [{k // 128, k % 128}]:\", dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"].grad[k // 128, k % 128])\n",
    "    print(f\"bf grad at [{k // 128, k % 128}]:\", dict(bf_model.named_parameters())[\"embeddings.word_embeddings.weight\"].grad[k // 128, k % 128])\n",
    "    print(f\"torch val at [{k // 128, k % 128}]:\", dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"][k // 128, k % 128])\n",
    "    print(f\"bf val at [{k // 128, k % 128}]:\", dict(bf_model.named_parameters())[\"embeddings.word_embeddings.weight\"].val[k // 128, k % 128])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 13.3900,  -7.8846,  -4.9994,  ...,  -7.8793,   1.5591,  -8.5621],\n",
       "         [ 20.8252, -15.4823,  -9.9196,  ...,   7.4338,  -3.8761,  -9.5488],\n",
       "         [ 24.2847, -20.2617,  -9.8825,  ...,   7.9612,  -6.3824, -13.3367],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]),\n",
       " DeviceArray([[ 13.3899493 ,  -7.88462552,  -4.99939799, ...,\n",
       "                -7.87930506,   1.55909437,  -8.56214457],\n",
       "              [ 20.8252424 , -15.48232402,  -9.91958797, ...,\n",
       "                 7.43374901,  -3.87605592,  -9.54876955],\n",
       "              [ 24.28469348, -20.26168625,  -9.88253943, ...,\n",
       "                 7.96123939,  -6.38237227, -13.33671944],\n",
       "              ...,\n",
       "              [  0.        ,   0.        ,   0.        , ...,\n",
       "                 0.        ,   0.        ,   0.        ],\n",
       "              [  0.        ,   0.        ,   0.        , ...,\n",
       "                 0.        ,   0.        ,   0.        ],\n",
       "              [  0.        ,   0.        ,   0.        , ...,\n",
       "                 0.        ,   0.        ,   0.        ]], dtype=float64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(torch_model.named_parameters())[\"embeddings.position_embeddings.weight\"].grad, dict(bf_model.named_parameters())[\"embeddings.position_embeddings.weight\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = jnp.abs(dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"].grad.numpy() - dict(bf_model.named_parameters())[\"embeddings.word_embeddings.weight\"].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(jnp.argmax(diff, axis=0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(2, 0), dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(diff.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.1018e-03, -3.0695e-02, -3.5295e-03,  ...,  1.8925e-02,\n",
       "          3.7396e-03, -2.9233e-03],\n",
       "        [-4.2748e-04, -3.6929e-02, -1.7168e-02,  ...,  2.9314e-02,\n",
       "         -1.0398e-02,  2.6772e-02],\n",
       "        [ 5.9418e-03,  4.2119e-03, -1.9566e-02,  ...,  1.6799e-02,\n",
       "         -2.7802e-02, -6.9017e-03],\n",
       "        ...,\n",
       "        [ 3.5573e-02, -1.5891e-02,  4.9951e-03,  ...,  5.4071e-03,\n",
       "         -1.1270e-02, -6.9528e-05],\n",
       "        [-8.7018e-03, -2.2516e-02,  3.1993e-03,  ...,  2.7591e-02,\n",
       "         -1.9554e-02,  2.4023e-03],\n",
       "        [-7.8904e-02, -7.5407e-02, -4.6660e-03,  ..., -5.3340e-03,\n",
       "         -4.4993e-02,  5.9842e-02]], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3072, 2, 128]), torch.Size([3072, 2]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = dict(torch_model.named_parameters())[\"embeddings.word_embeddings.weight\"]\n",
    "weight_grads = weight.grad\n",
    "weight_grads[weight_grads.nonzero()[0]], weight_grads.nonzero()[0]\n",
    "weight_grads[weight_grads.nonzero()].shape, weight_grads.nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-4.1018e-03, -3.0695e-02, -3.5295e-03,  ...,  1.8925e-02,\n",
       "           3.7396e-03, -2.9233e-03],\n",
       "         [-4.2748e-04, -3.6929e-02, -1.7168e-02,  ...,  2.9314e-02,\n",
       "          -1.0398e-02,  2.6772e-02],\n",
       "         [ 5.9418e-03,  4.2119e-03, -1.9566e-02,  ...,  1.6799e-02,\n",
       "          -2.7802e-02, -6.9017e-03],\n",
       "         ...,\n",
       "         [ 3.5573e-02, -1.5891e-02,  4.9951e-03,  ...,  5.4071e-03,\n",
       "          -1.1270e-02, -6.9528e-05],\n",
       "         [-8.7018e-03, -2.2516e-02,  3.1993e-03,  ...,  2.7591e-02,\n",
       "          -1.9554e-02,  2.4023e-03],\n",
       "         [-7.8904e-02, -7.5407e-02, -4.6660e-03,  ..., -5.3340e-03,\n",
       "          -4.4993e-02,  5.9842e-02]], requires_grad=True),\n",
       " DeviceArray([[-4.1018268e-03, -3.0694773e-02, -3.5295275e-03, ...,\n",
       "                1.8925212e-02,  3.7396429e-03, -2.9232893e-03],\n",
       "              [-4.2748044e-04, -3.6928687e-02, -1.7167933e-02, ...,\n",
       "                2.9313693e-02, -1.0397688e-02,  2.6771577e-02],\n",
       "              [ 5.9417770e-03,  4.2118742e-03, -1.9566311e-02, ...,\n",
       "                1.6798709e-02, -2.7802430e-02, -6.9016502e-03],\n",
       "              ...,\n",
       "              [ 3.5573229e-02, -1.5890833e-02,  4.9951361e-03, ...,\n",
       "                5.4070782e-03, -1.1269928e-02, -6.9528171e-05],\n",
       "              [-8.7017640e-03, -2.2515964e-02,  3.1992516e-03, ...,\n",
       "                2.7591001e-02, -1.9553846e-02,  2.4022695e-03],\n",
       "              [-7.8904152e-02, -7.5407349e-02, -4.6659894e-03, ...,\n",
       "               -5.3339875e-03, -4.4993456e-02,  5.9841771e-02]],            dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, dict(bf_model.named_parameters())[\"embeddings.word_embeddings.weight\"].val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
