{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbd049e1710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    "    BertSelfAttention,\n",
    "    BfBertSelfAttention,\n",
    "    BertSelfOutput,\n",
    "    BfBertSelfOutput,\n",
    "    BertAttention,\n",
    "    BfBertAttention,\n",
    "    BertLayer,\n",
    "    BfBertLayer,\n",
    "    BertEncoder,\n",
    "    BfBertEncoder,\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BfBaseModelOutputWithPastAndCrossAttentions,\n",
    ")\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from utils import check_bf_param_weights_match_torch, check_bf_model_outputs_match_torch_outputs, check_bf_param_grads_allclose_torch\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init torch and bf models\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"../../brunoflow/models/bert/config.json\")\n",
    "torch_model = BertEncoder(config)\n",
    "bf_model = BfBertEncoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init inputs to bf and torch models\n",
    "hidden_states_torch = torch.randn(size=(2, 19, 768))\n",
    "attention_mask_torch = torch.randn(size=(2, 1, 1, 19))\n",
    "\n",
    "hidden_states = jnp.array(hidden_states_torch.numpy(), dtype=jnp.float64)\n",
    "attention_mask = jnp.array(attention_mask_torch.numpy(), dtype=jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 377 ms, sys: 32.1 ms, total: 409 ms\n",
      "Wall time: 53.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_torch = torch_model(hidden_states_torch, attention_mask_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 09:40:40.105076: W external/org_tensorflow/tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.00MiB (rounded to 18874368)requested by op \n",
      "2022-12-26 09:40:40.109100: W external/org_tensorflow/tensorflow/tsl/framework/bfc_allocator.cc:492] ****************************************************************************************************\n",
      "2022-12-26 09:40:40.109193: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2153] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 18874368 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:   18.00MiB\n",
      "              constant allocation:         0B\n",
      "        maybe_live_out allocation:   18.00MiB\n",
      "     preallocated temp allocation:         0B\n",
      "                 total allocation:   36.00MiB\n",
      "              total fragmentation:         0B (0.00%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 18.00MiB\n",
      "\t\tEntry Parameter Subshape: f64[768,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 18.00MiB\n",
      "\t\tOperator: op_name=\"jit(transpose)/jit(main)/transpose[permutation=(1, 0)]\" source_file=\"/home/kevin/code/rycolab/brunoflow/brunoflow/func/linalg.py\" source_line=41\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f64[3072,768]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 18874368 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   18.00MiB\n              constant allocation:         0B\n        maybe_live_out allocation:   18.00MiB\n     preallocated temp allocation:         0B\n                 total allocation:   36.00MiB\n              total fragmentation:         0B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 18.00MiB\n\t\tEntry Parameter Subshape: f64[768,3072]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 18.00MiB\n\t\tOperator: op_name=\"jit(transpose)/jit(main)/transpose[permutation=(1, 0)]\" source_file=\"/home/kevin/code/rycolab/brunoflow/brunoflow/func/linalg.py\" source_line=41\n\t\tXLA Label: transpose\n\t\tShape: f64[3072,768]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/net/network.py:46\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/rycolab/transformers/src/transformers/models/bert/modeling_bf_bert.py:593\u001b[0m, in \u001b[0;36mBfBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGradient checkpointing is not implemented with brunoflow.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    571\u001b[0m     \u001b[39m# if use_cache:\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[39m#     logger.warning(\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     \u001b[39m#         \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \n\u001b[1;32m    592\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 593\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    594\u001b[0m         hidden_states,\n\u001b[1;32m    595\u001b[0m         attention_mask,\n\u001b[1;32m    596\u001b[0m         layer_head_mask,\n\u001b[1;32m    597\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    598\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    599\u001b[0m         past_key_value,\n\u001b[1;32m    600\u001b[0m         output_attentions,\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    603\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/net/network.py:46\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/rycolab/transformers/src/transformers/models/bert/modeling_bf_bert.py:520\u001b[0m, in \u001b[0;36mBfBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_size_feed_forward \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    518\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWARNING: self.chunk_size_feed_forward > 0, which we haven\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt accounted for in BF.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 520\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    521\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    522\u001b[0m )\n\u001b[1;32m    523\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    525\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/code/rycolab/transformers/src/transformers/bf_utils.py:256\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 256\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/code/rycolab/transformers/src/transformers/models/bert/modeling_bf_bert.py:533\u001b[0m, in \u001b[0;36mBfBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    532\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 533\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/net/network.py:46\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/rycolab/transformers/src/transformers/models/bert/modeling_bf_bert.py:441\u001b[0m, in \u001b[0;36mBfBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: bf\u001b[39m.\u001b[39mNode, input_tensor: bf\u001b[39m.\u001b[39mNode) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m bf\u001b[39m.\u001b[39mNode:\n\u001b[0;32m--> 441\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    442\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    443\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/net/network.py:46\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/net/linear.py:33\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m matmul(x, matrix_transpose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/func/linalg.py:58\u001b[0m, in \u001b[0;36mmatrix_transpose\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     56\u001b[0m axes[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     57\u001b[0m axes[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 58\u001b[0m \u001b[39mreturn\u001b[39;00m transpose(x, axes)\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/func/linalg.py:26\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(x, axes)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranspose\u001b[39m(x, axes):\n\u001b[1;32m     19\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m    Permute the axes of a tensor\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m    PyTorch equivalent: torch.Tensor.permute(x, axes)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m __transpose(x, axes)\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/func/function.py:58\u001b[0m, in \u001b[0;36mmake_function.<locals>.autodiff_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     56\u001b[0m in_vals \u001b[39m=\u001b[39m [ad\u001b[39m.\u001b[39mvalue(a) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[1;32m     57\u001b[0m \u001b[39m# Apply the forward function\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m out_val \u001b[39m=\u001b[39m forward(\u001b[39m*\u001b[39;49min_vals)\n\u001b[1;32m     59\u001b[0m \u001b[39m# print(\"args:\", args)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m# name = name_fct(*args) if name_fct is not None else None\u001b[39;00m\n\u001b[1;32m     61\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/func/linalg.py:41\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x, axes)\u001b[0m\n\u001b[1;32m     36\u001b[0m     inverse_perm \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(axes))[jnp\u001b[39m.\u001b[39margsort(jnp\u001b[39m.\u001b[39marray(axes))]\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mtranspose(out_grad, inverse_perm), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     40\u001b[0m __transpose \u001b[39m=\u001b[39m make_function(\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mlambda\u001b[39;00m x, axes: jnp\u001b[39m.\u001b[39;49mtranspose(x, axes),\n\u001b[1;32m     42\u001b[0m     transpose_backward,\n\u001b[1;32m     43\u001b[0m     construct_single_variable_fct_name(\u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m, (\u001b[39m\"\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m\"\u001b[39m,)),\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmatrix_transpose\u001b[39m(x):\n\u001b[1;32m     48\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m    Permute the last two axes of a tensor\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m    PyTorch equivalent: torch.transpose(x, -1, -2)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:558\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    556\u001b[0m axes_ \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(ndim(a))[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mif\u001b[39;00m axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m axes\n\u001b[1;32m    557\u001b[0m axes_ \u001b[39m=\u001b[39m [_canonicalize_axis(i, ndim(a)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m axes_]\n\u001b[0;32m--> 558\u001b[0m \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39;49mtranspose(a, axes_)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/lax/lax.py:960\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(operand, permutation)\u001b[0m\n\u001b[1;32m    958\u001b[0m   \u001b[39mreturn\u001b[39;00m type_cast(Array, operand)\n\u001b[1;32m    959\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 960\u001b[0m   \u001b[39mreturn\u001b[39;00m transpose_p\u001b[39m.\u001b[39;49mbind(operand, permutation\u001b[39m=\u001b[39;49mpermutation)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/core.py:329\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    327\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    328\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 329\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/core.py:332\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 332\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    333\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/core.py:712\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 712\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/dispatch.py:115\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m compiled_fun \u001b[39m=\u001b[39m xla_primitive_callable(prim, \u001b[39m*\u001b[39munsafe_map(arg_spec, args),\n\u001b[1;32m    114\u001b[0m                                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fun(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/dispatch.py:200\u001b[0m, in \u001b[0;36mxla_primitive_callable.<locals>.<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    197\u001b[0m compiled \u001b[39m=\u001b[39m _xla_callable_uncached(lu\u001b[39m.\u001b[39mwrap_init(prim_fun), device, \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    198\u001b[0m                                   prim\u001b[39m.\u001b[39mname, donated_invars, \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39marg_specs)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prim\u001b[39m.\u001b[39mmultiple_results:\n\u001b[0;32m--> 200\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: compiled(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m   \u001b[39mreturn\u001b[39;00m compiled\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/dispatch.py:895\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, input_handler, output_buffer_counts, result_handler, has_unordered_effects, ordered_effects, kept_var_idx, has_host_callbacks, *args)\u001b[0m\n\u001b[1;32m    893\u001b[0m     runtime_token \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m   out_flat \u001b[39m=\u001b[39m compiled\u001b[39m.\u001b[39;49mexecute(in_flat)\n\u001b[1;32m    896\u001b[0m check_special(name, out_flat)\n\u001b[1;32m    897\u001b[0m out_bufs \u001b[39m=\u001b[39m unflatten(out_flat, output_buffer_counts)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 18874368 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   18.00MiB\n              constant allocation:         0B\n        maybe_live_out allocation:   18.00MiB\n     preallocated temp allocation:         0B\n                 total allocation:   36.00MiB\n              total fragmentation:         0B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 18.00MiB\n\t\tEntry Parameter Subshape: f64[768,3072]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 18.00MiB\n\t\tOperator: op_name=\"jit(transpose)/jit(main)/transpose[permutation=(1, 0)]\" source_file=\"/home/kevin/code/rycolab/brunoflow/brunoflow/func/linalg.py\" source_line=41\n\t\tXLA Label: transpose\n\t\tShape: f64[3072,768]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_bf = bf_model(hidden_states, attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that forward pass for bf works and matches output shape with torch\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    # Handle case where outputs is a tuple/list and not just a single item\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i] \n",
    "        assert(out_torch.shape == out_bf.shape)\n",
    "\n",
    "else:\n",
    "    assert(outputs_torch.shape == outputs_bf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertSelfAttention to file\n",
    "save_path = \"bertlayer_torch.pt\"\n",
    "torch.save(torch_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state dict for BertSelfAttention into BF and check weights, outputs, and backprop\n",
    "bf_model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check weights of BF model and Torch model match exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight attention.self.query.bias for bf and torch are equal? True\n",
      "Value of param weight attention.self.query.weight for bf and torch are equal? True\n",
      "Value of param weight attention.self.key.bias for bf and torch are equal? True\n",
      "Value of param weight attention.self.key.weight for bf and torch are equal? True\n",
      "Value of param weight attention.self.value.bias for bf and torch are equal? True\n",
      "Value of param weight attention.self.value.weight for bf and torch are equal? True\n",
      "Value of param weight attention.output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight attention.output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight attention.output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight attention.output.LayerNorm.bias for bf and torch are equal? True\n",
      "Value of param weight intermediate.dense.bias for bf and torch are equal? True\n",
      "Value of param weight intermediate.dense.weight for bf and torch are equal? True\n",
      "Value of param weight output.dense.bias for bf and torch are equal? True\n",
      "Value of param weight output.dense.weight for bf and torch are equal? True\n",
      "Value of param weight output.LayerNorm.weight for bf and torch are equal? True\n",
      "Value of param weight output.LayerNorm.bias for bf and torch are equal? True\n"
     ]
    }
   ],
   "source": [
    "# Check weights match\n",
    "check_bf_param_weights_match_torch(bf_model, torch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model output after forward pass matches for BF and Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of bf and torch are within 1e-06? True\n"
     ]
    }
   ],
   "source": [
    "# Check output from forward passes match for bf and torch\n",
    "torch_model.train(False)\n",
    "outputs_bf = bf_model(hidden_states=hidden_states, attention_mask=attention_mask)\n",
    "outputs_torch = torch_model(hidden_states=hidden_states_torch, attention_mask=attention_mask_torch)\n",
    "\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i]\n",
    "        check_bf_model_outputs_match_torch_outputs(out_bf, out_torch, atol=1e-6)\n",
    "else:\n",
    "    check_bf_model_outputs_match_torch_outputs(outputs_bf, outputs_torch, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check grad after backward pass matches for BF and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.8 ms, sys: 1.09 ms, total: 46.9 ms\n",
      "Wall time: 45.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Torch backward pass\n",
    "torch_model.train(True)\n",
    "\n",
    "if isinstance(outputs_torch, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    outputs_torch[0].backward(gradient=torch.ones_like(outputs_torch[0]))\n",
    "else:\n",
    "    outputs_torch.backward(gradient=torch.ones_like(outputs_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 1min 7s, total: 2min 46s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# BF backward pass\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    outputs_bf[0].backprop(values_to_compute=(\"grad\",))\n",
    "else:\n",
    "    outputs_bf.backprop(values_to_compute=(\"grad\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad of param attention.self.query.bias for bf and torch are within 1e-05? True\n",
      "Grad of param attention.self.query.weight for bf and torch are within 1e-05? True\n",
      "Grad of param attention.self.key.bias for bf and torch are within 1e-05? True\n",
      "Grad of param attention.self.key.weight for bf and torch are within 1e-05? True\n",
      "Grad of param attention.self.value.bias for bf and torch are within 1e-05? True\n",
      "Grad of param attention.self.value.weight for bf and torch are within 1e-05? True\n",
      "Grad of param attention.output.dense.bias for bf and torch are within 1e-05? True\n",
      "Grad of param attention.output.dense.weight for bf and torch are within 1e-05? True\n",
      "Grad of param attention.output.LayerNorm.weight for bf and torch are within 1e-05? True\n",
      "Grad of param attention.output.LayerNorm.bias for bf and torch are within 1e-05? True\n",
      "Grad of param intermediate.dense.bias for bf and torch are within 1e-05? True\n",
      "Grad of param intermediate.dense.weight for bf and torch are within 1e-05? True\n",
      "Grad of param output.dense.bias for bf and torch are within 1e-05? True\n",
      "Grad of param output.dense.weight for bf and torch are within 1e-05? True\n",
      "Grad of param output.LayerNorm.weight for bf and torch are within 1e-05? True\n",
      "Grad of param output.LayerNorm.bias for bf and torch are within 1e-05? True\n"
     ]
    }
   ],
   "source": [
    "# Run the actual check\n",
    "check_bf_param_grads_allclose_torch(bf_model, torch_model, atol=1e-5, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
