{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1ea3b236f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    "    BertSelfAttention,\n",
    "    BfBertSelfAttention,\n",
    "    BertSelfOutput,\n",
    "    BfBertSelfOutput,\n",
    "    BertAttention,\n",
    "    BfBertAttention,\n",
    "    BertIntermediate,\n",
    "    BfBertIntermediate\n",
    ")\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from utils import check_bf_param_weights_match_torch, check_bf_model_outputs_match_torch_outputs, check_bf_param_grads_allclose_torch\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 23:51:08.681952: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Init torch and bf models\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"../../brunoflow/models/bert/config.json\")\n",
    "torch_model = BertIntermediate(config)\n",
    "bf_model = BfBertIntermediate(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init inputs to bf and torch models\n",
    "hidden_states_torch = torch.randn(size=(2, 19, 768))\n",
    "\n",
    "hidden_states = jnp.array(hidden_states_torch.numpy(), dtype=jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "outputs_torch = torch_model(hidden_states_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "outputs_bf = bf_model(hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that forward pass for bf works and matches output shape with torch\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    # Handle case where outputs is a tuple/list and not just a single item\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i] \n",
    "        assert(out_torch.shape == out_bf.shape)\n",
    "\n",
    "else:\n",
    "    assert(outputs_torch.shape == outputs_bf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertSelfAttention to file\n",
    "save_path = \"bertintermediate_torch.pt\"\n",
    "torch.save(torch_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state dict for BertSelfAttention into BF and check weights, outputs, and backprop\n",
    "bf_model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check weights of BF model and Torch model match exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight dense.bias for bf and torch are equal? True\n",
      "Value of param weight dense.weight for bf and torch are equal? True\n"
     ]
    }
   ],
   "source": [
    "# Check weights match\n",
    "check_bf_param_weights_match_torch(bf_model, torch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model output after forward pass matches for BF and Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of bf and torch are within 1e-06? True\n"
     ]
    }
   ],
   "source": [
    "# Check output from forward passes match for bf and torch\n",
    "torch_model.train(False)\n",
    "outputs_bf = bf_model(hidden_states=hidden_states)\n",
    "outputs_torch = torch_model(hidden_states=hidden_states_torch)\n",
    "\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i]\n",
    "        check_bf_model_outputs_match_torch_outputs(out_bf, out_torch, atol=1e-6)\n",
    "else:\n",
    "    check_bf_model_outputs_match_torch_outputs(outputs_bf, outputs_torch, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check grad after backward pass matches for BF and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 12.4 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1664405705473/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Torch backward pass\n",
    "torch_model.train(True)\n",
    "\n",
    "if isinstance(outputs_torch, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    outputs_torch[0].backward(gradient=torch.ones_like(outputs_torch[0]))\n",
    "else:\n",
    "    outputs_torch.backward(gradient=torch.ones_like(outputs_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 11 µs\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory allocating 54509174784 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     outputs_bf[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mbackprop(values_to_compute\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m\"\u001b[39m,))\n\u001b[1;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     outputs_bf\u001b[39m.\u001b[39;49mbackprop(values_to_compute\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mgrad\u001b[39;49m\u001b[39m\"\u001b[39;49m,))\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/ad/node.py:255\u001b[0m, in \u001b[0;36mNode.backprop\u001b[0;34m(self, values_to_compute, save_leaf_grads_only, verbose)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, num_uses:\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad),\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__compute_num_uses()\n\u001b[0;32m--> 255\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__backprop(values_to_compute\u001b[39m=\u001b[39;49mvalues_to_compute, verbose\u001b[39m=\u001b[39;49mverbose, save_leaf_grads_only\u001b[39m=\u001b[39;49msave_leaf_grads_only)\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/ad/node.py:474\u001b[0m, in \u001b[0;36mNode.__backprop\u001b[0;34m(self, values_to_compute, save_leaf_grads_only, verbose)\u001b[0m\n\u001b[1;32m    472\u001b[0m input_vals \u001b[39m=\u001b[39m [inp\u001b[39m.\u001b[39mval \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inp, Node) \u001b[39melse\u001b[39;00m inp \u001b[39mfor\u001b[39;00m inp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs]\n\u001b[1;32m    473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m values_to_compute:\n\u001b[0;32m--> 474\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_and_accumulate_grads_for_inputs(\n\u001b[1;32m    475\u001b[0m         input_vals\u001b[39m=\u001b[39;49minput_vals, backward_func\u001b[39m=\u001b[39;49mbackward_func, verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmax_grad\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m values_to_compute:\n\u001b[1;32m    478\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_and_accumulate_max_pos_and_neg_grads_for_inputs(\n\u001b[1;32m    479\u001b[0m         input_vals\u001b[39m=\u001b[39minput_vals, backward_func\u001b[39m=\u001b[39mbackward_func, verbose\u001b[39m=\u001b[39mverbose\n\u001b[1;32m    480\u001b[0m     )\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/ad/node.py:260\u001b[0m, in \u001b[0;36mNode._compute_and_accumulate_grads_for_inputs\u001b[0;34m(self, input_vals, backward_func, verbose)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compute_and_accumulate_grads_for_inputs\u001b[39m(\u001b[39mself\u001b[39m, input_vals, backward_func, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    258\u001b[0m     \u001b[39m# The 'adjoint' is the partial derivative of the final node in the graph\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m#   (typically the loss) w.r.t. the value at this Node.\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     adjoints \u001b[39m=\u001b[39m backward_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrad, \u001b[39m*\u001b[39;49minput_vals)\n\u001b[1;32m    262\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(input_vals) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(adjoints)\n\u001b[1;32m    263\u001b[0m     \u001b[39m# Accumulate these adjoints into the gradients for this Node's inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/func/function.py:46\u001b[0m, in \u001b[0;36mmake_function.<locals>.backward_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m kwarg \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backward_args:\n\u001b[1;32m     44\u001b[0m         \u001b[39m# print(f\"WARNING: backward function named {backward.__name__} does not have an argument named {kwarg}. Deleting kwarg.\")\u001b[39;00m\n\u001b[1;32m     45\u001b[0m         \u001b[39mdel\u001b[39;00m kwargs[kwarg]\n\u001b[0;32m---> 46\u001b[0m ret \u001b[39m=\u001b[39m backward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, Iterable) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, jnp\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     48\u001b[0m     ret \u001b[39m=\u001b[39m [ret]\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/func/function.py:80\u001b[0m, in \u001b[0;36mpointwise_backward.<locals>.backward_func\u001b[0;34m(out_val, out_grad, product_fn, *input_vals)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_func\u001b[39m(out_val, out_grad, \u001b[39m*\u001b[39minput_vals, product_fn\u001b[39m=\u001b[39m\u001b[39m__mul__\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[39m# Invoke the pointwise backward function\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     local_adjoints \u001b[39m=\u001b[39m pointwise_back_fn(out_val, \u001b[39m*\u001b[39;49minput_vals)\n\u001b[1;32m     81\u001b[0m     \u001b[39m# Make sure the returned adjoints are a list we can iterate over\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(local_adjoints, Iterable) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(local_adjoints, jnp\u001b[39m.\u001b[39mndarray):\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/func/activations.py:123\u001b[0m, in \u001b[0;36mgelu_exact_backward\u001b[0;34m(out, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgelu_exact_backward\u001b[39m(out, x):\n\u001b[0;32m--> 123\u001b[0m     jac \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mjacfwd(_gelu_exact)(x)\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39msum(jac, axis\u001b[39m=\u001b[39m\u001b[39mtuple\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(jac\u001b[39m.\u001b[39mshape) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape))))\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/api.py:1288\u001b[0m, in \u001b[0;36mjacfwd.<locals>.jacfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[1;32m   1287\u001b[0m   pushfwd \u001b[39m=\u001b[39m partial(_jvp, f_partial, dyn_args)\n\u001b[0;32m-> 1288\u001b[0m   y, jac \u001b[39m=\u001b[39m vmap(pushfwd, out_axes\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))(_std_basis(dyn_args))\n\u001b[1;32m   1289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1290\u001b[0m   pushfwd \u001b[39m=\u001b[39m partial(_jvp, f_partial, dyn_args, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/api.py:1467\u001b[0m, in \u001b[0;36m_std_basis\u001b[0;34m(pytree)\u001b[0m\n\u001b[1;32m   1465\u001b[0m ndim \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mmap\u001b[39m(np\u001b[39m.\u001b[39msize, leaves))\n\u001b[1;32m   1466\u001b[0m dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mresult_type(\u001b[39m*\u001b[39mleaves)\n\u001b[0;32m-> 1467\u001b[0m flat_basis \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mnumpy\u001b[39m.\u001b[39;49meye(ndim, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1468\u001b[0m \u001b[39mreturn\u001b[39;00m _unravel_array_into_pytree(pytree, \u001b[39m1\u001b[39m, \u001b[39mNone\u001b[39;00m, flat_basis)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:2218\u001b[0m, in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype)\u001b[0m\n\u001b[1;32m   2216\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnegative dimensions are not allowed, got \u001b[39m\u001b[39m{\u001b[39;00mN\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mM\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2217\u001b[0m k \u001b[39m=\u001b[39m operator\u001b[39m.\u001b[39mindex(k)\n\u001b[0;32m-> 2218\u001b[0m \u001b[39mreturn\u001b[39;00m lax_internal\u001b[39m.\u001b[39;49m_eye(_jnp_dtype(dtype), (N_int, M_int), k)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/lax/lax.py:1233\u001b[0m, in \u001b[0;36m_eye\u001b[0;34m(dtype, shape, offset)\u001b[0m\n\u001b[1;32m   1231\u001b[0m offset \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(offset)\n\u001b[1;32m   1232\u001b[0m dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(dtype)\n\u001b[0;32m-> 1233\u001b[0m bool_eye \u001b[39m=\u001b[39m eq(add(broadcasted_iota(np\u001b[39m.\u001b[39;49mint32, shape, \u001b[39m0\u001b[39;49m), np\u001b[39m.\u001b[39mint32(offset)),\n\u001b[1;32m   1234\u001b[0m               broadcasted_iota(np\u001b[39m.\u001b[39mint32, shape, \u001b[39m1\u001b[39m))\n\u001b[1;32m   1235\u001b[0m \u001b[39mreturn\u001b[39;00m convert_element_type_p\u001b[39m.\u001b[39mbind(bool_eye, new_dtype\u001b[39m=\u001b[39mdtype, weak_type\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/lax/lax.py:1226\u001b[0m, in \u001b[0;36mbroadcasted_iota\u001b[0;34m(dtype, shape, dimension)\u001b[0m\n\u001b[1;32m   1223\u001b[0m static_shape \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(d, core\u001b[39m.\u001b[39mTracer) \u001b[39melse\u001b[39;00m d \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m shape]\n\u001b[1;32m   1224\u001b[0m dimension \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mconcrete_or_error(\n\u001b[1;32m   1225\u001b[0m     \u001b[39mint\u001b[39m, dimension, \u001b[39m\"\u001b[39m\u001b[39mdimension argument of lax.broadcasted_iota\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m \u001b[39mreturn\u001b[39;00m iota_p\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49mdynamic_shape, dtype\u001b[39m=\u001b[39;49mdtype, shape\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(static_shape),\n\u001b[1;32m   1227\u001b[0m                    dimension\u001b[39m=\u001b[39;49mdimension)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/core.py:329\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    327\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    328\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 329\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/core.py:332\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 332\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    333\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/core.py:712\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 712\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/dispatch.py:115\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m compiled_fun \u001b[39m=\u001b[39m xla_primitive_callable(prim, \u001b[39m*\u001b[39munsafe_map(arg_spec, args),\n\u001b[1;32m    114\u001b[0m                                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fun(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/dispatch.py:200\u001b[0m, in \u001b[0;36mxla_primitive_callable.<locals>.<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    197\u001b[0m compiled \u001b[39m=\u001b[39m _xla_callable_uncached(lu\u001b[39m.\u001b[39mwrap_init(prim_fun), device, \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    198\u001b[0m                                   prim\u001b[39m.\u001b[39mname, donated_invars, \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39marg_specs)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prim\u001b[39m.\u001b[39mmultiple_results:\n\u001b[0;32m--> 200\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: compiled(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m   \u001b[39mreturn\u001b[39;00m compiled\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-hf/lib/python3.9/site-packages/jax/_src/dispatch.py:895\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, input_handler, output_buffer_counts, result_handler, has_unordered_effects, ordered_effects, kept_var_idx, has_host_callbacks, *args)\u001b[0m\n\u001b[1;32m    893\u001b[0m     runtime_token \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m   out_flat \u001b[39m=\u001b[39m compiled\u001b[39m.\u001b[39;49mexecute(in_flat)\n\u001b[1;32m    896\u001b[0m check_special(name, out_flat)\n\u001b[1;32m    897\u001b[0m out_bufs \u001b[39m=\u001b[39m unflatten(out_flat, output_buffer_counts)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory allocating 54509174784 bytes."
     ]
    }
   ],
   "source": [
    "%time \n",
    "# BF backward pass\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    outputs_bf[0].backprop(values_to_compute=(\"grad\",))\n",
    "else:\n",
    "    outputs_bf.backprop(values_to_compute=(\"grad\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad of param self.query.bias for bf and torch are within 1e-05? True\n",
      "Grad of param self.query.weight for bf and torch are within 1e-05? True\n",
      "Grad of param self.key.bias for bf and torch are within 1e-05? True\n",
      "Grad of param self.key.weight for bf and torch are within 1e-05? True\n",
      "Grad of param self.value.bias for bf and torch are within 1e-05? True\n",
      "Grad of param self.value.weight for bf and torch are within 1e-05? True\n",
      "Grad of param output.dense.bias for bf and torch are within 1e-05? True\n",
      "Grad of param output.dense.weight for bf and torch are within 1e-05? True\n",
      "Grad of param output.LayerNorm.weight for bf and torch are within 1e-05? True\n",
      "Grad of param output.LayerNorm.bias for bf and torch are within 1e-05? True\n"
     ]
    }
   ],
   "source": [
    "# Run the actual check\n",
    "check_bf_param_grads_allclose_torch(bf_model, torch_model, atol=1e-5, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
