{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ab03e012910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "from jax import numpy as jnp\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    BertForMaskedLM, \n",
    "    BertTokenizer, \n",
    "    BertTokenizerFast, \n",
    "    BertEmbeddings,\n",
    "    BfBertEmbeddings,\n",
    "    BertConfig,\n",
    "    BertSelfAttention,\n",
    "    BfBertSelfAttention,\n",
    "    BertSelfOutput,\n",
    "    BfBertSelfOutput,\n",
    "    BertAttention,\n",
    "    BfBertAttention,\n",
    "    BertIntermediate,\n",
    "    BfBertIntermediate\n",
    ")\n",
    "from brunoflow.ad.utils import check_node_equals_tensor, check_node_allclose_tensor\n",
    "from utils import check_bf_param_weights_match_torch, check_bf_model_outputs_match_torch_outputs, check_bf_param_grads_allclose_torch\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init torch and bf models\n",
    "config = BertConfig.from_pretrained(pretrained_model_name_or_path=\"../../brunoflow/models/bert/config.json\")\n",
    "torch_model = BertIntermediate(config)\n",
    "bf_model = BfBertIntermediate(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init inputs to bf and torch models\n",
    "hidden_states_torch = torch.randn(size=(2, 19, 768))\n",
    "\n",
    "hidden_states = jnp.array(hidden_states_torch.numpy(), dtype=jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 ms, sys: 2.17 ms, total: 15.9 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_torch = torch_model(hidden_states_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 587 ms, sys: 277 ms, total: 864 ms\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_bf = bf_model(hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that forward pass for bf works and matches output shape with torch\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    # Handle case where outputs is a tuple/list and not just a single item\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i] \n",
    "        assert(out_torch.shape == out_bf.shape)\n",
    "\n",
    "else:\n",
    "    assert(outputs_torch.shape == outputs_bf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save torch BertSelfAttention to file\n",
    "save_path = \"bertintermediate_torch.pt\"\n",
    "torch.save(torch_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state dict for BertSelfAttention into BF and check weights, outputs, and backprop\n",
    "bf_model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check weights of BF model and Torch model match exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of param weight dense.bias for bf and torch are equal? True\n",
      "Value of param weight dense.weight for bf and torch are equal? True\n"
     ]
    }
   ],
   "source": [
    "# Check weights match\n",
    "check_bf_param_weights_match_torch(bf_model, torch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model output after forward pass matches for BF and Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of bf and torch are within 1e-06? True\n"
     ]
    }
   ],
   "source": [
    "# Check output from forward passes match for bf and torch\n",
    "torch_model.train(False)\n",
    "outputs_bf = bf_model(hidden_states=hidden_states)\n",
    "outputs_torch = torch_model(hidden_states=hidden_states_torch)\n",
    "\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    for i in range(len(outputs_bf)):\n",
    "        out_bf, out_torch = outputs_bf[i], outputs_torch[i]\n",
    "        check_bf_model_outputs_match_torch_outputs(out_bf, out_torch, atol=1e-6)\n",
    "else:\n",
    "    check_bf_model_outputs_match_torch_outputs(outputs_bf, outputs_torch, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check grad after backward pass matches for BF and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 ms, sys: 3.77 ms, total: 19 ms\n",
      "Wall time: 16.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Torch backward pass\n",
    "torch_model.train(True)\n",
    "\n",
    "if isinstance(outputs_torch, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    outputs_torch[0].backward(gradient=torch.ones_like(outputs_torch[0]))\n",
    "else:\n",
    "    outputs_torch.backward(gradient=torch.ones_like(outputs_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 828 ms, total: 2.25 s\n",
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BF backward pass\n",
    "if isinstance(outputs_bf, (list, tuple)):\n",
    "    assert len(outputs_bf) == len(outputs_torch)\n",
    "    outputs_bf[0].backprop(values_to_compute=(\"grad\",))\n",
    "else:\n",
    "    outputs_bf.backprop(values_to_compute=(\"grad\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad of param dense.bias for bf and torch are within 1e-05? True\n",
      "Grad of param dense.weight for bf and torch are within 1e-05? True\n"
     ]
    }
   ],
   "source": [
    "# Run the actual check\n",
    "check_bf_param_grads_allclose_torch(bf_model, torch_model, atol=1e-5, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.08071289 19.88536307 16.41011589 ... 22.49699207 18.58312123\n",
      " 15.14929407]\n",
      "[[ 4.06865117  1.80183488  3.17271962 ... -1.23772789  0.27722289\n",
      "  -7.01184791]\n",
      " [ 3.83343693 -1.17917966  2.12415311 ... -2.8559995   0.73369748\n",
      "  -1.34719317]\n",
      " [ 4.91057663  0.60769482 -0.23988259 ... -6.17080812 -0.62998463\n",
      "  -4.87208344]\n",
      " ...\n",
      " [-1.69226959 -1.22749706  2.55204808 ...  0.11834742 -1.72904177\n",
      "  -2.54002883]\n",
      " [ 3.26504851 -2.34438119 -1.36697079 ... -1.72814144  2.87235288\n",
      "   0.3346037 ]\n",
      " [ 0.10640387 -1.74101877 -1.42268893 ... -5.03681767  0.27159493\n",
      "  -3.36159435]]\n"
     ]
    }
   ],
   "source": [
    "print(bf_model.dense.bias.grad)\n",
    "print(bf_model.dense.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17.0807, 19.8854, 16.4101,  ..., 22.4970, 18.5831, 15.1493])\n",
      "tensor([[ 4.0687,  1.8018,  3.1727,  ..., -1.2377,  0.2772, -7.0118],\n",
      "        [ 3.8334, -1.1792,  2.1242,  ..., -2.8560,  0.7337, -1.3472],\n",
      "        [ 4.9106,  0.6077, -0.2399,  ..., -6.1708, -0.6300, -4.8721],\n",
      "        ...,\n",
      "        [-1.6923, -1.2275,  2.5520,  ...,  0.1183, -1.7290, -2.5400],\n",
      "        [ 3.2650, -2.3444, -1.3670,  ..., -1.7281,  2.8724,  0.3346],\n",
      "        [ 0.1064, -1.7410, -1.4227,  ..., -5.0368,  0.2716, -3.3616]])\n"
     ]
    }
   ],
   "source": [
    "print(torch_model.dense.bias.grad)\n",
    "print(torch_model.dense.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
